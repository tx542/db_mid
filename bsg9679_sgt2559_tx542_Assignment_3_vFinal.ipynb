{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c031bb",
   "metadata": {},
   "source": [
    "<h1 align=center><font size=6>Data Bootcamp</font></h1>\n",
    "<h2 align=center><font size=6>Fall 2021</font></h2>\n",
    "<h2 align=center><font size=6>Assignment 3</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7002cd",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8630dee",
   "metadata": {},
   "source": [
    "<h2 align = \"center\">Names and NetIDs: </h2>\n",
    "<h3 align = \"center\"> Names: Brandon Gao, Siegrid Tuttle, Michael Xu </h3>\n",
    "<h3 align = \"center\"> NetIDs: bsg9679, sgt2559, tx542 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897f2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: be sure to run the import statements first, before anything else... \n",
    "# import the relevant libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "# set the plotnine figure size\n",
    "plotnine.options.figure_size = (8, 6)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsRegressor as knn\n",
    "# Random Forests\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "# Train-Test Split, Cross-Validation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# KNN - Classification\n",
    "from sklearn.neighbors import KNeighborsClassifier as knnc\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# Random Forests - Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier as rf_clf\n",
    "\n",
    "# ROC-AUC Curves\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc, roc_auc_score, precision_recall_curve\n",
    "\n",
    "# Data Imbalance\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# LogisticRegression and PCA - Dimension Reduction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# filter out unnecessary warnings... \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0020c76",
   "metadata": {},
   "source": [
    "### Problem 1:\n",
    "Predicting prices: Using any of the methods for prediction you have learned (With the exception of linear regression!) , use the dataset in this Kaggle page:\n",
    "https://www.kaggle.com/altavish/boston-housing-dataset\n",
    "and find a good **prediction model for the the median value of housing (MEDV)**. The variables in the dataset are as follows\n",
    "\n",
    "- **CRIM**: Per capita crime rate by town\n",
    "- **ZN**: Proportion of residential land zoned for lots over 25,000 sq. ft\n",
    "- **INDUS**: Proportion of non-retail business acres per town\n",
    "- **CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- **NOX**: Nitric oxide concentration (parts per 10 million)\n",
    "- **RM**: Average number of rooms per dwelling\n",
    "- **AGE**: Proportion of owner-occupied units built prior to 1940\n",
    "- **DIS**: Weighted distances to five Boston employment centers\n",
    "- **RAD**: Index of accessibility to radial highways\n",
    "- **TAX**: Full-value property tax rate per 10,000\n",
    "- **PTRATIO**: Pupil-teacher ratio by town\n",
    "- **B**: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town\n",
    "- **LSTAT**: Percentage of lower status of the population\n",
    "- **MEDV**: Median value of owner-occupied homes in $1000s\n",
    "\n",
    "Make sure to deal with **null values** and find the **best hyperparameters** you can for your choice of model (use train/test split or crossvalidation). Watch out for **outliers**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4146be",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d0055",
   "metadata": {},
   "source": [
    "As also mentioned by the Professor, let us start by taking a look at some descriptive statistics of the column variables in the DataFrame for this question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d800694",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD  TAX  \\\n",
       "0   0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900    1  296   \n",
       "1   0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671    2  242   \n",
       "2   0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671    2  242   \n",
       "3   0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622    3  222   \n",
       "4   0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622    3  222   \n",
       "5   0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622    3  222   \n",
       "6   0.08829  12.5   7.87   NaN  0.524  6.012   66.6  5.5605    5  311   \n",
       "7   0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505    5  311   \n",
       "8   0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821    5  311   \n",
       "9   0.17004  12.5   7.87   NaN  0.524  6.004   85.9  6.5921    5  311   \n",
       "10  0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467    5  311   \n",
       "11  0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267    5  311   \n",
       "12  0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509    5  311   \n",
       "13  0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075    4  307   \n",
       "14  0.63796   0.0   8.14   NaN  0.538  6.096   84.5  4.4619    4  307   \n",
       "15  0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986    4  307   \n",
       "16  1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986    4  307   \n",
       "17  0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579    4  307   \n",
       "18  0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965    4  307   \n",
       "19  0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965    4  307   \n",
       "\n",
       "    PTRATIO       B  LSTAT  MEDV  \n",
       "0      15.3  396.90   4.98  24.0  \n",
       "1      17.8  396.90   9.14  21.6  \n",
       "2      17.8  392.83   4.03  34.7  \n",
       "3      18.7  394.63   2.94  33.4  \n",
       "4      18.7  396.90    NaN  36.2  \n",
       "5      18.7  394.12   5.21  28.7  \n",
       "6      15.2  395.60  12.43  22.9  \n",
       "7      15.2  396.90  19.15  27.1  \n",
       "8      15.2  386.63  29.93  16.5  \n",
       "9      15.2  386.71  17.10  18.9  \n",
       "10     15.2  392.52  20.45  15.0  \n",
       "11     15.2  396.90  13.27  18.9  \n",
       "12     15.2  390.50  15.71  21.7  \n",
       "13     21.0  396.90   8.26  20.4  \n",
       "14     21.0  380.02  10.26  18.2  \n",
       "15     21.0  395.62   8.47  19.9  \n",
       "16     21.0  386.85   6.58  23.1  \n",
       "17     21.0  386.75  14.67  17.5  \n",
       "18     21.0  288.99  11.69  20.2  \n",
       "19     21.0  390.95  11.28  18.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1 = pd.read_csv(\"HousingData.csv\")\n",
    "df_p1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7570b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.611874</td>\n",
       "      <td>11.211934</td>\n",
       "      <td>11.083992</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.720192</td>\n",
       "      <td>23.388876</td>\n",
       "      <td>6.835896</td>\n",
       "      <td>0.255340</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>27.999513</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.155871</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.175000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.253715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.560263</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>93.975000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  486.000000  486.000000  486.000000  486.000000  506.000000  506.000000   \n",
       "mean     3.611874   11.211934   11.083992    0.069959    0.554695    6.284634   \n",
       "std      8.720192   23.388876    6.835896    0.255340    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081900    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.253715    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.560263   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  486.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.518519    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     27.999513    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.175000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     76.800000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     93.975000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  486.000000  506.000000  \n",
       "mean    12.715432   22.532806  \n",
       "std      7.155871    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      7.125000   17.025000  \n",
       "50%     11.430000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb601b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD          int64\n",
       "TAX          int64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "MEDV       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7615b3e",
   "metadata": {},
   "source": [
    "Actually, let us also graph the **histogram (overlaid with KDE estimation line) for each of our column variables** (which are, fortuitously, properly recognized by Pandas as numeric data types):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f144c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hist(var_x_label, df):\n",
    "    '''\n",
    "    A function that can make a histogram, overlaid with KDE \n",
    "    estimation line, for the given column label (corresponding \n",
    "    to a column variable) of the given DataFrame.\n",
    "    '''\n",
    "    obj = (ggplot(df.dropna(subset = [var_x_label]), aes(x = var_x_label)) \n",
    "           + geom_histogram(aes(y = \"stat(density)\"), alpha = 0.5, fill = \"green\")\n",
    "           + geom_density(color = \"red\", alpha = 0.5)\n",
    "           + ggtitle('Histogram for the Density Distribution of \"{}\" with KDE Line'\\\n",
    "                     .format(var_x_label))\n",
    "           + ylab(\"Density\")\n",
    "           + xlab(var_x_label)\n",
    "           + theme_bw())\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a683248",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_var in df_p1.columns:\n",
    "    make_hist(x_var, df_p1).save(\"p_1_hist/hist_{}.png\".format(x_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e76b7",
   "metadata": {},
   "source": [
    "Feel free to go to our `\"p_1_hist\"` subdirectory to check out the histogram for each of the column variables. We will embed the following histograms, as the corresponding column variables seem to have **issues of significant outliers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64f3a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (304338875)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_hist(\"B\", df_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7505a6a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (304700986)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_hist(\"CRIM\", df_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2dd5182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (275609869)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_hist(\"ZN\", df_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce231834",
   "metadata": {},
   "source": [
    "Now, what if we **bin those variables suffering from significant outliers (which are otherwise continuous) and see how representative each interval can be of the total variation for a given variable**!\n",
    "\n",
    "Let us start by defining a function that can plot pie charts. We will also define transformative functions that can bin the continuous variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dac7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie(var_name, df, custom_colors = None):\n",
    "    '''\n",
    "    A function that can make a pie chart for the given column label \n",
    "    (corresponding to a column variable) of the given DataFrame\n",
    "    '''\n",
    "    plt.clf() # clear any previous figure window\n",
    "    plt.figure(figsize = (8, 6), dpi = 100) # set figure size\n",
    "    plt.pie(df[var_name].value_counts(), \n",
    "            labels = df[var_name].value_counts().index,\n",
    "            autopct = '%.2f%%', # customized colors below:\n",
    "            colors = [\"red\", \"blue\", \"orange\", \"green\", \"lightskyblue\", \"gold\"],\n",
    "            wedgeprops = {\"alpha\": 0.4}) # increase transparency for visual effects\n",
    "    plt.title('Pie Chart of \"{}\"'.format(var_name))\n",
    "    plt.axis('equal')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ccd44",
   "metadata": {},
   "source": [
    "After some detailed discussions, we have unanimously decided that we will **deal with those variables with significant outliers** (as illustrated above in the **histograms**, as well as below in the **pie charts** \\[of binned column variables\\]) by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8453b",
   "metadata": {},
   "source": [
    "- In models that use **B**, **rows with values under 300 will be dropped** because they represent a few outliers, not the bulk of the data (as shown in the pie chart below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c577d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_B(B_value):\n",
    "    if B_value < 100:\n",
    "        return '0-100'\n",
    "    elif 100 <= B_value < 200:\n",
    "        return \"100-200\"\n",
    "    elif 200 <= B_value < 300:\n",
    "        return \"200-300\"\n",
    "    elif 300 <= B_value <= 400:\n",
    "        return \"300-400\"\n",
    "\n",
    "df_p1['B_by_range'] = df_p1['B'].apply(lambda x: categorize_B(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ece5bce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pie(\"B_by_range\", df_p1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0b5b1",
   "metadata": {},
   "source": [
    "- In models that use **CRIM**, **all rows above 25 will be dropped** because they represent a few outliers, not the bulk of the data (as shown in the pie chart below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa5979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_CRIM(CRIM_value):\n",
    "    if CRIM_value < 25:\n",
    "        return '0-25'\n",
    "    elif 25 <= CRIM_value < 50:\n",
    "        return \"25-50\"\n",
    "    elif 50 <= CRIM_value < 75:\n",
    "        return \"50-75\"\n",
    "    elif 75 <= CRIM_value <= 100:\n",
    "        return \"75-100\"\n",
    "\n",
    "df_p1['CRIM_by_range'] = df_p1['CRIM'].apply(lambda x: categorize_CRIM(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c8b7b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pie(\"CRIM_by_range\", df_p1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962580c",
   "metadata": {},
   "source": [
    "- **Not using ZN**: As shown above, the vast majority of neighborhoods have no or few lots zoned for more than 25,000 acres, so there is **not enough variation for it to be a useful variable in our models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab018fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_ZN(ZN_value):\n",
    "    if ZN_value == 0:\n",
    "        return '0'\n",
    "    elif 0 < ZN_value < 25:\n",
    "        return '0(Exclusive)-25'\n",
    "    elif 25 <= ZN_value < 50:\n",
    "        return \"25-50\"\n",
    "    elif 50 <= ZN_value < 75:\n",
    "        return \"50-75\"\n",
    "    elif 75 <= ZN_value <= 100:\n",
    "        return \"75-100\"\n",
    "\n",
    "df_p1['ZN_by_range'] = df_p1['ZN'].apply(lambda x: categorize_ZN(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3906c2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pie(\"ZN_by_range\", df_p1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26067781",
   "metadata": {},
   "source": [
    "Also, with regard to how we will deal with observations with `np.NaN`, we will **only drop the observations that have `np.NaN` in the column variables that are specifically used for a model** (i.e. we want to make sure that the data we are passing into a model for fitting does not contain any `np.NaN`, while trying to preserve as many observations as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ccfcac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us start by getting rid of the outliers, as specified above\n",
    "df_p1_new = df_p1[(df_p1[\"B\"] >= 300) \n",
    "                  & (df_p1[\"CRIM\"] <= 25)]\\\n",
    ".drop(columns = ['ZN', 'ZN_by_range', 'B_by_range', 'CRIM_by_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae3b783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0    0.00632   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1    0.02731   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2    0.02729   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3    0.03237   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4    0.06905   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "..       ...    ...   ...    ...    ...   ...     ...  ...  ...      ...   \n",
       "501  0.06263  11.93   0.0  0.573  6.593  69.1  2.4786    1  273     21.0   \n",
       "502  0.04527  11.93   0.0  0.573  6.120  76.7  2.2875    1  273     21.0   \n",
       "503  0.06076  11.93   0.0  0.573  6.976  91.0  2.1675    1  273     21.0   \n",
       "504  0.10959  11.93   0.0  0.573  6.794  89.3  2.3889    1  273     21.0   \n",
       "505  0.04741  11.93   0.0  0.573  6.030   NaN  2.5050    1  273     21.0   \n",
       "\n",
       "          B  LSTAT  MEDV  \n",
       "0    396.90   4.98  24.0  \n",
       "1    396.90   9.14  21.6  \n",
       "2    392.83   4.03  34.7  \n",
       "3    394.63   2.94  33.4  \n",
       "4    396.90    NaN  36.2  \n",
       "..      ...    ...   ...  \n",
       "501  391.99    NaN  22.4  \n",
       "502  396.90   9.08  20.6  \n",
       "503  396.90   5.64  23.9  \n",
       "504  393.45   6.48  22.0  \n",
       "505  396.90   7.88  11.9  \n",
       "\n",
       "[431 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p1_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42305bda",
   "metadata": {},
   "source": [
    "Because our group tackled the second question first (as it involves classification models, which we learned more recently about and appeared more interesting to us), we had gained more experiences with regards to the procedural approaches to these types of questions.\n",
    "\n",
    "Before formulating our **potential models based on our understanding of pertinent socioeconomic theories related to the market pricing of housing (as assets)**, we will firstly define **a function, `predict_MEDV` that will perform all the necessary analyses with our inputs** of model name (`model_num`), pandas DataFrame (`df`), list of X-variables (`var_labels`), Y-variable to be explained/predicted (`y_label`), a range within which the optimal hyperparameter shall be found (`min_param`, `max_param`, and `inc_param`), choice of regressor object (e.g. `knn` or `rf`) through the input `regressor_obj`, the name of the approach (`approach_name`), as well as optional arguments specifying the number of CV groups (`num_cv`) and whether PCA dimension-reduction shall be used on the X-variables (`is_PCA` and `PCA_param`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e5eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_MEDV(model_num, df, var_labels, y_label, min_param, \n",
    "                 max_param, inc_param, regressor_obj, approach_name,\n",
    "                 num_cv = 5, is_PCA = False, PCA_param = 1.0):\n",
    "    '''\n",
    "    (c) Brandon Gao (bsg9679), Siegrid Tuttle (sgt2559), and Michael Xu (tx542)\n",
    "    Data Bootcamp | Fall 2021 | NYU Stern\n",
    "    \n",
    "    -------------------------------------------------------------------------------------\n",
    "    \n",
    "    This function takes in the parameters:\n",
    "    - model_num: the model number (ordinal),\n",
    "    - df: a Pandas DataFrame (`df`),\n",
    "    - var_labels: a list-like/iterable container object (`var_labels`) listing the \n",
    "    column labels that shall be used as the explanatory variable,\n",
    "    - y_label: a column label that is the explained variable (y variable/label),\n",
    "    - a customizable range to find the optimal hyperparameter, where\n",
    "        - min_param is the lower bound,\n",
    "        - max_param is the upper bound (not inclusive),\n",
    "        - inc_param is the increment\n",
    "    - regressor_obj: the regressor object to use in this function (rf or knn, for Problem 1),\n",
    "    - approach_name: name of the approach (regressor object),\n",
    "    - num_cv: a customizable number of cross-validation groups (default is 5),\n",
    "    - is_PCA: boolean input to indicate whether PCA will be used,\n",
    "    - PCA_param: parameter to pass into the PCA object, only needed if is_PCA is True\n",
    "    \n",
    "    It will then use the approach passed into the function through regressor_obj, \n",
    "    with the optimal hyperparameter that has the maximum\n",
    "    cross-validation score, to construct the optimal regressor object.\n",
    "    \n",
    "    It will then conduct a random train-test split, and\n",
    "    print the test fit score.\n",
    "    \n",
    "    * Note that all random_state is 0, for the purpose of replicability.\n",
    "    '''\n",
    "    \n",
    "    # some user input checks...\n",
    "    \n",
    "    # DataFrame data type\n",
    "    if (type(df) != pd.core.frame.DataFrame):\n",
    "        print('Dataset is not a Pandas DataFrame object!')\n",
    "        return None\n",
    "    \n",
    "    # checks for the existence of x labels\n",
    "    if [(item in df.columns) for item in var_labels].count(True)\\\n",
    "    < len(var_labels):\n",
    "        print('Not all explanatory variables are in the given DataFrame!')\n",
    "        return None\n",
    "        \n",
    "    # and also for the y label \n",
    "    if (type(y_label) != str) or (y_label not in df.columns):\n",
    "        print('Invalid y label!')\n",
    "        return None\n",
    "    \n",
    "    # also for the num_cv optional input\n",
    "    if (type(num_cv) != int):\n",
    "        print('Invalid CV number! Function will proceed with the default value, 5.')\n",
    "        num_cv = 5\n",
    "        \n",
    "    # only drop na for the col vars to be used to fit models\n",
    "    # to preserve as many obs as necessary/possible\n",
    "    all_drop_var = var_labels + [y_label]\n",
    "    SUB_DF = df[all_drop_var].dropna()\n",
    "    \n",
    "    # ensure that not `too many` rows were dropped by reporting shape[0]\n",
    "    print(\"The number of observations in the given DataFrame is: {:.0f}\".\\\n",
    "         format(df.shape[0]))\n",
    "    print(\"The valid number of observations left is: {:.0f}\\n\".\\\n",
    "         format(SUB_DF.shape[0]))\n",
    "    \n",
    "    \n",
    "    # determine whether PCA will be used  \n",
    "    if is_PCA:\n",
    "        \n",
    "        # standardize the explanatory variables \n",
    "        # (as indicated by the labels)\n",
    "\n",
    "        X_vars_st = StandardScaler().fit_transform(SUB_DF[var_labels])\n",
    "        \n",
    "        # construct the PCA object and transform the X variables\n",
    "        # according to the rule as specified in the PCA_param\n",
    "        pca_obj = PCA(PCA_param).fit(X_vars_st)\n",
    "        X_VARS = pca_obj.transform(X_vars_st)\n",
    "        \n",
    "        print(\"As instructed, PCA transformation is used on the given X labels.\")\n",
    "        print(\"{:.2f}% of all variations of the X labels is preserved.\\n\".\\\n",
    "             format(PCA_param * 100))\n",
    "    \n",
    "    else:\n",
    "        # if PCA is not used: \n",
    "        \n",
    "        # only drop na for the col vars to be used to fit models\n",
    "        # to preserve as many obs as necessary/possible\n",
    "        X_VARS = SUB_DF[var_labels]\n",
    "        \n",
    "    \n",
    "    # --->>> use CV, experiment with the hyperparameter, within the given range <<<---\n",
    "    score_array = [cross_val_score(regressor_obj(i), \n",
    "                                   X = X_VARS, \n",
    "                                   y = SUB_DF[y_label], \n",
    "                                   cv = num_cv).mean() for i \\\n",
    "                   in range(min_param, max_param, inc_param)]\n",
    "\n",
    "    # construct the df to record the score and corresponding hyperparameter (n_neighbors)\n",
    "    cv_df = pd.DataFrame(score_array, columns = ['score'])\n",
    "    cv_df['hyperparameter'] = list(range(min_param, max_param, inc_param))\n",
    "\n",
    "    # let us find the entry with the maximum cv score\n",
    "    # and the corresponding hyperparameter\n",
    "    opt_obs = cv_df.loc[cv_df['score'] == cv_df['score'].max()]\n",
    "    opt_param = int(opt_obs['hyperparameter'].iloc[0, ])\n",
    "    # take the first optimal parameter, in case that there are multiple\n",
    "    \n",
    "    # report the optimal hyperparameter and CV score:\n",
    "    print(\"Using the {} approach, the optimal hyperparameter is: {} (within the range of ({},{},{}).\\n\"\\\n",
    "          .format(approach_name, opt_param, min_param, max_param, inc_param))\n",
    "    print(\"And the optimal CV score is: {:.4f}.\\n\".\\\n",
    "         format(float(opt_obs['score'].iloc[0, ])))\n",
    "    \n",
    "    # --->>> make the optimal prediction, using a train-test split <<<--- \n",
    "    # shuffle and split training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_VARS, \n",
    "                                                        SUB_DF[y_label], \n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state = 0)\n",
    "\n",
    "    # use the optimal hyperparameter, fit the train data, \n",
    "    # obtain score using the test (\"never-seen-before\") data\n",
    "    train_score = regressor_obj(opt_param).fit(X = X_train, y = Y_train)\\\n",
    "    .score(X = X_train, y = Y_train)\n",
    "    test_score = regressor_obj(opt_param).fit(X = X_train, y = Y_train)\\\n",
    "    .score(X = X_test, y = Y_test)\n",
    "    \n",
    "    # --->>> report the train-train and train-test scores as derived above  <<<---\n",
    "    \n",
    "    print('''Using the {} approach, based on a random train-test split (using random_state = 0):\\n'''\\\n",
    "         .format(approach_name))\n",
    "    print(\"The score, fitted on the train data, of the train data is: {:4f};\"\\\n",
    "         .format(train_score))\n",
    "    print(\"The score, fitted on the train data, of the test data is: {:4f}.\\n\"\\\n",
    "         .format(test_score))\n",
    "    \n",
    "    # line of division\n",
    "    print('-'*90 + '\\n')\n",
    "    \n",
    "    return {'model_num': model_num,\n",
    "            'model_approach': approach_name,\n",
    "            'opt_hyperparam': opt_param,\n",
    "            'opt_cv_score': float(opt_obs['score'].iloc[0, ]),\n",
    "            'train_train_score': train_score,\n",
    "            'train_test_score': test_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b697cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this command to learn more about our function\n",
    "# (we have our own customized docstring!)\n",
    "predict_MEDV?\n",
    "\n",
    "# we reserve copyright of this function (to the extent available/applicable)\n",
    "# and may use it in our final project\n",
    "\n",
    "# (c) Brandon Gao (bsg9679), Siegrid Tuttle (sgt2559), and Michael Xu (tx542)\n",
    "# Data Bootcamp | Fall 2021 | NYU Stern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee44ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDV_all_recs = [] # also, a container \n",
    "# to keep track of all the records of experiments with \n",
    "# different models and approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b89a04",
   "metadata": {},
   "source": [
    "### Infrastructure Model:\n",
    "\n",
    "Our first model is based on the infrastructure of the neighborhood: benefits of its geographic location, land use, age of buildings, and other factors that have to do with the physical space of the neighborhood: \n",
    " \n",
    "- **INDUS**: Proportion of non-retail business acres per town       \n",
    "- **CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)     \n",
    "- **AGE**: Proportion of owner-occupied units built prior to 1940        \n",
    "- **DIS**: Weighted distances to five Boston employment centers          \n",
    "- **RAD**: Index of accessibility to radial highways            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "291292e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 381\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 76 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: -0.6605.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.203016;\n",
      "The score, fitted on the train data, of the test data is: 0.049346.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MEDV_all_recs.append(predict_MEDV(\"Infrastructure\", df_p1_new, \n",
    "             [\"INDUS\", \"CHAS\", \"AGE\", \"DIS\", \"RAD\"],\n",
    "             \"MEDV\", 1, 401, 1, knn, \"KNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65c5b4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 381\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 136 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: -0.6454.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.926759;\n",
      "The score, fitted on the train data, of the test data is: 0.163883.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MEDV_all_recs.append(predict_MEDV(\"Infrastructure\", df_p1_new, \n",
    "             [\"INDUS\", \"CHAS\", \"AGE\", \"DIS\", \"RAD\"],\n",
    "             \"MEDV\", 100, 201, 1, rf, \"RF\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c54411",
   "metadata": {},
   "source": [
    "### Demand Model \n",
    "\n",
    "For our second model, we will utilize the following explanatory variables that may influence the willingness aspect of consumers' demand for a particular housing option. The variables range from utility considerations to safety and life quality ones. \n",
    "\n",
    "- **CRIM**: Per capita crime rate by town                                                 \n",
    "- **CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)                                    \n",
    "- **RM**: Average number of rooms per dwelling                                 \n",
    "- **DIS**: Weighted distances to five Boston employment centers                           \n",
    "- **RAD**: Index of accessibility to radial highways                          \n",
    "- **PTRATIO**: Pupil-teacher ratio by town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "929d9301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 414\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 13 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: -0.2420.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.565045;\n",
      "The score, fitted on the train data, of the test data is: 0.530898.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MEDV_all_recs.append(predict_MEDV(\"Demand\", df_p1_new, \n",
    "             [\"CRIM\", \"CHAS\", \"RM\", \"DIS\", \"RAD\", \"PTRATIO\"],\n",
    "             \"MEDV\", 1, 401, 1, knn, \"KNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c1597a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 414\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 106 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: 0.1719.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.950778;\n",
      "The score, fitted on the train data, of the test data is: 0.753863.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MEDV_all_recs.append(predict_MEDV(\"Demand\", df_p1_new, \n",
    "             [\"CRIM\", \"CHAS\", \"RM\", \"DIS\", \"RAD\", \"PTRATIO\"],\n",
    "             \"MEDV\", 100, 201, 1, rf, \"RF\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f03841",
   "metadata": {},
   "source": [
    "### Demographic Model\n",
    "\n",
    "Our third model investigates the demographic factors of the immediate environment (neighborhood/town) of the housing asset, which might also affect consumers' demand (mostly through negative externality, impacting their willingness to purchase). \n",
    "\n",
    "- **CRIM**: Per capita crime rate by town\n",
    "- **NOX**: Nitric oxide concentration (parts per 10 million)\n",
    "- **PTRATIO**: Pupil-teacher ratio by town\n",
    "- **B**: 1000(Bk — 0.63)², where Bk is the proportion of \\[people of African American descent\\] by town\n",
    "- **LSTAT**: Percentage of lower status of the population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deb1237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 411\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 14 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: 0.3696.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.666974;\n",
      "The score, fitted on the train data, of the test data is: 0.655857.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MEDV_all_recs.append(predict_MEDV(\"Demographic\", df_p1_new, \n",
    "             [\"CRIM\", \"NOX\", \"PTRATIO\", \"B\", \"LSTAT\"],\n",
    "             \"MEDV\", 1, 401, 1, knn, \"KNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b36b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 411\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 128 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: 0.4939.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.972145;\n",
      "The score, fitted on the train data, of the test data is: 0.704654.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MEDV_all_recs.append(predict_MEDV(\"Demographic\", df_p1_new, \n",
    "             [\"CRIM\", \"NOX\", \"PTRATIO\", \"B\", \"LSTAT\"],\n",
    "             \"MEDV\", 100, 201, 1, rf, \"RF\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe5c9b0",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "906f2e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "100.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 49 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: -0.2233.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.284959;\n",
      "The score, fitted on the train data, of the test data is: 0.396555.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "95.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 11 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: 0.4898.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.751484;\n",
      "The score, fitted on the train data, of the test data is: 0.837076.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "90.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 15 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: 0.4617.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.728076;\n",
      "The score, fitted on the train data, of the test data is: 0.830863.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "85.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 11 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: 0.4600.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.753525;\n",
      "The score, fitted on the train data, of the test data is: 0.845075.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "80.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the KNN approach, the optimal hyperparameter is: 17 (within the range of (1,401,1).\n",
      "\n",
      "And the optimal CV score is: 0.4443.\n",
      "\n",
      "Using the KNN approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.698082;\n",
      "The score, fitted on the train data, of the test data is: 0.830044.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in [1, 0.95, 0.90, 0.85, 0.8]:\n",
    "    MEDV_all_recs.append(predict_MEDV(\"PCA {:.0f}% (All X Vars)\".format(var * 100), df_p1_new, \n",
    "                 ['CRIM', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \n",
    "                  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'],\n",
    "                 \"MEDV\", 1, 401, 1, knn, \"KNN\", is_PCA = True, PCA_param = var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8a84136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "100.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 105 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: -0.6093.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.863086;\n",
      "The score, fitted on the train data, of the test data is: 0.276005.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "95.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 156 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: 0.0762.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.959330;\n",
      "The score, fitted on the train data, of the test data is: 0.880351.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "90.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 110 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: 0.1374.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.952604;\n",
      "The score, fitted on the train data, of the test data is: 0.898981.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "85.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 100 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: 0.1330.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.955909;\n",
      "The score, fitted on the train data, of the test data is: 0.896342.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "The number of observations in the given DataFrame is: 431\n",
      "The valid number of observations left is: 362\n",
      "\n",
      "As instructed, PCA transformation is used on the given X labels.\n",
      "80.00% of all variations of the X labels is preserved.\n",
      "\n",
      "Using the RF approach, the optimal hyperparameter is: 152 (within the range of (100,201,1).\n",
      "\n",
      "And the optimal CV score is: 0.1556.\n",
      "\n",
      "Using the RF approach, based on a random train-test split (using random_state = 0):\n",
      "\n",
      "The score, fitted on the train data, of the train data is: 0.953851;\n",
      "The score, fitted on the train data, of the test data is: 0.890687.\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for var in [1, 0.95, 0.90, 0.85, 0.8]:\n",
    "    MEDV_all_recs.append(predict_MEDV(\"PCA {:.0f}% (All X Vars)\".format(var * 100), df_p1_new, \n",
    "                 ['CRIM', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \n",
    "                  'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'],\n",
    "                 \"MEDV\", 100, 201, 1, rf, \"RF\", is_PCA = True, PCA_param = var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94fa3e8",
   "metadata": {},
   "source": [
    "### Some Brief Model Comparison and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ddba8",
   "metadata": {},
   "source": [
    "See the DataFrame below for the **Optimal CV**, **Train-Test** (model fit on train data, score on test data), and then **Train-Train** (model fit on train data, score also on train data) scores for each theoretical model and approach (double indices), including PCA with varying parameters (% of variance left):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a9055ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>train_train_score</th>\n",
       "      <th>train_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Infrastructure</th>\n",
       "      <th>KNN</th>\n",
       "      <td>76</td>\n",
       "      <td>-0.660480</td>\n",
       "      <td>0.203016</td>\n",
       "      <td>0.049346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>136</td>\n",
       "      <td>-0.645418</td>\n",
       "      <td>0.926759</td>\n",
       "      <td>0.163883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Demand</th>\n",
       "      <th>KNN</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.242010</td>\n",
       "      <td>0.565045</td>\n",
       "      <td>0.530898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>106</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.950778</td>\n",
       "      <td>0.753863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Demographic</th>\n",
       "      <th>KNN</th>\n",
       "      <td>14</td>\n",
       "      <td>0.369606</td>\n",
       "      <td>0.666974</td>\n",
       "      <td>0.655857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>128</td>\n",
       "      <td>0.493901</td>\n",
       "      <td>0.972145</td>\n",
       "      <td>0.704654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 100% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.223305</td>\n",
       "      <td>0.284959</td>\n",
       "      <td>0.396555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.489815</td>\n",
       "      <td>0.751484</td>\n",
       "      <td>0.837076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>15</td>\n",
       "      <td>0.461747</td>\n",
       "      <td>0.728076</td>\n",
       "      <td>0.830863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.460020</td>\n",
       "      <td>0.753525</td>\n",
       "      <td>0.845075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>17</td>\n",
       "      <td>0.444343</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>0.830044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 100% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>105</td>\n",
       "      <td>-0.609288</td>\n",
       "      <td>0.863086</td>\n",
       "      <td>0.276005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>156</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>0.959330</td>\n",
       "      <td>0.880351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>110</td>\n",
       "      <td>0.137395</td>\n",
       "      <td>0.952604</td>\n",
       "      <td>0.898981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>100</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.955909</td>\n",
       "      <td>0.896342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>152</td>\n",
       "      <td>0.155647</td>\n",
       "      <td>0.953851</td>\n",
       "      <td>0.890687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      opt_hyperparam  opt_cv_score  \\\n",
       "model_num             model_approach                                 \n",
       "Infrastructure        KNN                         76     -0.660480   \n",
       "                      RF                         136     -0.645418   \n",
       "Demand                KNN                         13     -0.242010   \n",
       "                      RF                         106      0.171865   \n",
       "Demographic           KNN                         14      0.369606   \n",
       "                      RF                         128      0.493901   \n",
       "PCA 100% (All X Vars) KNN                         49     -0.223305   \n",
       "PCA 95% (All X Vars)  KNN                         11      0.489815   \n",
       "PCA 90% (All X Vars)  KNN                         15      0.461747   \n",
       "PCA 85% (All X Vars)  KNN                         11      0.460020   \n",
       "PCA 80% (All X Vars)  KNN                         17      0.444343   \n",
       "PCA 100% (All X Vars) RF                         105     -0.609288   \n",
       "PCA 95% (All X Vars)  RF                         156      0.076184   \n",
       "PCA 90% (All X Vars)  RF                         110      0.137395   \n",
       "PCA 85% (All X Vars)  RF                         100      0.133000   \n",
       "PCA 80% (All X Vars)  RF                         152      0.155647   \n",
       "\n",
       "                                      train_train_score  train_test_score  \n",
       "model_num             model_approach                                       \n",
       "Infrastructure        KNN                      0.203016          0.049346  \n",
       "                      RF                       0.926759          0.163883  \n",
       "Demand                KNN                      0.565045          0.530898  \n",
       "                      RF                       0.950778          0.753863  \n",
       "Demographic           KNN                      0.666974          0.655857  \n",
       "                      RF                       0.972145          0.704654  \n",
       "PCA 100% (All X Vars) KNN                      0.284959          0.396555  \n",
       "PCA 95% (All X Vars)  KNN                      0.751484          0.837076  \n",
       "PCA 90% (All X Vars)  KNN                      0.728076          0.830863  \n",
       "PCA 85% (All X Vars)  KNN                      0.753525          0.845075  \n",
       "PCA 80% (All X Vars)  KNN                      0.698082          0.830044  \n",
       "PCA 100% (All X Vars) RF                       0.863086          0.276005  \n",
       "PCA 95% (All X Vars)  RF                       0.959330          0.880351  \n",
       "PCA 90% (All X Vars)  RF                       0.952604          0.898981  \n",
       "PCA 85% (All X Vars)  RF                       0.955909          0.896342  \n",
       "PCA 80% (All X Vars)  RF                       0.953851          0.890687  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(MEDV_all_recs)\n",
    "df.set_index(['model_num', 'model_approach'], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc86f3",
   "metadata": {},
   "source": [
    "If we sort the DataFrame above **by Optimal CV, Train-Test, and then Train-Train score (in that order of priority) from highest to lowest**, we can clearly see that, in general (especially for the cases where PCA is involved), the **KNN approach** performs **more consistently and reliably** than the **RF approach**.\n",
    "\n",
    "As illustrated in the sorted DataFrame below, the **KNN models** have **less variation/fluctuation across different score measures and tend to perform better in cross-validation** (which means that the KNN results can be more generalizable to other possible random train-test splits), whereas the **RF models**, despite the high Train-Test and Train-Train scores for this specific train-test splits, **do not have very high cross-validation scores (across different train-test splits)**.\n",
    "\n",
    "With regards to the best model overall—it appears that the **PCA dimension-reduction works quite well with both the KNN and RF approaches**, except that the optimal parameter (% of variance left) can differ for each specific approach (95% for KNN and 80% for RF, if we weigh Optimal CV score over Train-Test score and over Train-Train score). \n",
    "\n",
    "On the other hand, it also appears that the **Demographic model, implemented using the RF approach**, has **the best balance between cross-validation (model generalizability) and train-test score (for this specific split) for this specific run**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b714535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>train_train_score</th>\n",
       "      <th>train_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Demographic</th>\n",
       "      <th>RF</th>\n",
       "      <td>128</td>\n",
       "      <td>0.493901</td>\n",
       "      <td>0.972145</td>\n",
       "      <td>0.704654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.489815</td>\n",
       "      <td>0.751484</td>\n",
       "      <td>0.837076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>15</td>\n",
       "      <td>0.461747</td>\n",
       "      <td>0.728076</td>\n",
       "      <td>0.830863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.460020</td>\n",
       "      <td>0.753525</td>\n",
       "      <td>0.845075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>17</td>\n",
       "      <td>0.444343</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>0.830044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic</th>\n",
       "      <th>KNN</th>\n",
       "      <td>14</td>\n",
       "      <td>0.369606</td>\n",
       "      <td>0.666974</td>\n",
       "      <td>0.655857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand</th>\n",
       "      <th>RF</th>\n",
       "      <td>106</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.950778</td>\n",
       "      <td>0.753863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>152</td>\n",
       "      <td>0.155647</td>\n",
       "      <td>0.953851</td>\n",
       "      <td>0.890687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>110</td>\n",
       "      <td>0.137395</td>\n",
       "      <td>0.952604</td>\n",
       "      <td>0.898981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>100</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.955909</td>\n",
       "      <td>0.896342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>156</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>0.959330</td>\n",
       "      <td>0.880351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 100% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.223305</td>\n",
       "      <td>0.284959</td>\n",
       "      <td>0.396555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand</th>\n",
       "      <th>KNN</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.242010</td>\n",
       "      <td>0.565045</td>\n",
       "      <td>0.530898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 100% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>105</td>\n",
       "      <td>-0.609288</td>\n",
       "      <td>0.863086</td>\n",
       "      <td>0.276005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Infrastructure</th>\n",
       "      <th>RF</th>\n",
       "      <td>136</td>\n",
       "      <td>-0.645418</td>\n",
       "      <td>0.926759</td>\n",
       "      <td>0.163883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>76</td>\n",
       "      <td>-0.660480</td>\n",
       "      <td>0.203016</td>\n",
       "      <td>0.049346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      opt_hyperparam  opt_cv_score  \\\n",
       "model_num             model_approach                                 \n",
       "Demographic           RF                         128      0.493901   \n",
       "PCA 95% (All X Vars)  KNN                         11      0.489815   \n",
       "PCA 90% (All X Vars)  KNN                         15      0.461747   \n",
       "PCA 85% (All X Vars)  KNN                         11      0.460020   \n",
       "PCA 80% (All X Vars)  KNN                         17      0.444343   \n",
       "Demographic           KNN                         14      0.369606   \n",
       "Demand                RF                         106      0.171865   \n",
       "PCA 80% (All X Vars)  RF                         152      0.155647   \n",
       "PCA 90% (All X Vars)  RF                         110      0.137395   \n",
       "PCA 85% (All X Vars)  RF                         100      0.133000   \n",
       "PCA 95% (All X Vars)  RF                         156      0.076184   \n",
       "PCA 100% (All X Vars) KNN                         49     -0.223305   \n",
       "Demand                KNN                         13     -0.242010   \n",
       "PCA 100% (All X Vars) RF                         105     -0.609288   \n",
       "Infrastructure        RF                         136     -0.645418   \n",
       "                      KNN                         76     -0.660480   \n",
       "\n",
       "                                      train_train_score  train_test_score  \n",
       "model_num             model_approach                                       \n",
       "Demographic           RF                       0.972145          0.704654  \n",
       "PCA 95% (All X Vars)  KNN                      0.751484          0.837076  \n",
       "PCA 90% (All X Vars)  KNN                      0.728076          0.830863  \n",
       "PCA 85% (All X Vars)  KNN                      0.753525          0.845075  \n",
       "PCA 80% (All X Vars)  KNN                      0.698082          0.830044  \n",
       "Demographic           KNN                      0.666974          0.655857  \n",
       "Demand                RF                       0.950778          0.753863  \n",
       "PCA 80% (All X Vars)  RF                       0.953851          0.890687  \n",
       "PCA 90% (All X Vars)  RF                       0.952604          0.898981  \n",
       "PCA 85% (All X Vars)  RF                       0.955909          0.896342  \n",
       "PCA 95% (All X Vars)  RF                       0.959330          0.880351  \n",
       "PCA 100% (All X Vars) KNN                      0.284959          0.396555  \n",
       "Demand                KNN                      0.565045          0.530898  \n",
       "PCA 100% (All X Vars) RF                       0.863086          0.276005  \n",
       "Infrastructure        RF                       0.926759          0.163883  \n",
       "                      KNN                      0.203016          0.049346  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = ['opt_cv_score', 'train_test_score', 'train_train_score'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84984268",
   "metadata": {},
   "source": [
    "See other potential sorting orders below, in case you are interested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f38a377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>train_train_score</th>\n",
       "      <th>train_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>110</td>\n",
       "      <td>0.137395</td>\n",
       "      <td>0.952604</td>\n",
       "      <td>0.898981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>100</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.955909</td>\n",
       "      <td>0.896342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>152</td>\n",
       "      <td>0.155647</td>\n",
       "      <td>0.953851</td>\n",
       "      <td>0.890687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>156</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>0.959330</td>\n",
       "      <td>0.880351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.460020</td>\n",
       "      <td>0.753525</td>\n",
       "      <td>0.845075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.489815</td>\n",
       "      <td>0.751484</td>\n",
       "      <td>0.837076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>15</td>\n",
       "      <td>0.461747</td>\n",
       "      <td>0.728076</td>\n",
       "      <td>0.830863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>17</td>\n",
       "      <td>0.444343</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>0.830044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand</th>\n",
       "      <th>RF</th>\n",
       "      <td>106</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.950778</td>\n",
       "      <td>0.753863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Demographic</th>\n",
       "      <th>RF</th>\n",
       "      <td>128</td>\n",
       "      <td>0.493901</td>\n",
       "      <td>0.972145</td>\n",
       "      <td>0.704654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>14</td>\n",
       "      <td>0.369606</td>\n",
       "      <td>0.666974</td>\n",
       "      <td>0.655857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand</th>\n",
       "      <th>KNN</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.242010</td>\n",
       "      <td>0.565045</td>\n",
       "      <td>0.530898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PCA 100% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.223305</td>\n",
       "      <td>0.284959</td>\n",
       "      <td>0.396555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>105</td>\n",
       "      <td>-0.609288</td>\n",
       "      <td>0.863086</td>\n",
       "      <td>0.276005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Infrastructure</th>\n",
       "      <th>RF</th>\n",
       "      <td>136</td>\n",
       "      <td>-0.645418</td>\n",
       "      <td>0.926759</td>\n",
       "      <td>0.163883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>76</td>\n",
       "      <td>-0.660480</td>\n",
       "      <td>0.203016</td>\n",
       "      <td>0.049346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      opt_hyperparam  opt_cv_score  \\\n",
       "model_num             model_approach                                 \n",
       "PCA 90% (All X Vars)  RF                         110      0.137395   \n",
       "PCA 85% (All X Vars)  RF                         100      0.133000   \n",
       "PCA 80% (All X Vars)  RF                         152      0.155647   \n",
       "PCA 95% (All X Vars)  RF                         156      0.076184   \n",
       "PCA 85% (All X Vars)  KNN                         11      0.460020   \n",
       "PCA 95% (All X Vars)  KNN                         11      0.489815   \n",
       "PCA 90% (All X Vars)  KNN                         15      0.461747   \n",
       "PCA 80% (All X Vars)  KNN                         17      0.444343   \n",
       "Demand                RF                         106      0.171865   \n",
       "Demographic           RF                         128      0.493901   \n",
       "                      KNN                         14      0.369606   \n",
       "Demand                KNN                         13     -0.242010   \n",
       "PCA 100% (All X Vars) KNN                         49     -0.223305   \n",
       "                      RF                         105     -0.609288   \n",
       "Infrastructure        RF                         136     -0.645418   \n",
       "                      KNN                         76     -0.660480   \n",
       "\n",
       "                                      train_train_score  train_test_score  \n",
       "model_num             model_approach                                       \n",
       "PCA 90% (All X Vars)  RF                       0.952604          0.898981  \n",
       "PCA 85% (All X Vars)  RF                       0.955909          0.896342  \n",
       "PCA 80% (All X Vars)  RF                       0.953851          0.890687  \n",
       "PCA 95% (All X Vars)  RF                       0.959330          0.880351  \n",
       "PCA 85% (All X Vars)  KNN                      0.753525          0.845075  \n",
       "PCA 95% (All X Vars)  KNN                      0.751484          0.837076  \n",
       "PCA 90% (All X Vars)  KNN                      0.728076          0.830863  \n",
       "PCA 80% (All X Vars)  KNN                      0.698082          0.830044  \n",
       "Demand                RF                       0.950778          0.753863  \n",
       "Demographic           RF                       0.972145          0.704654  \n",
       "                      KNN                      0.666974          0.655857  \n",
       "Demand                KNN                      0.565045          0.530898  \n",
       "PCA 100% (All X Vars) KNN                      0.284959          0.396555  \n",
       "                      RF                       0.863086          0.276005  \n",
       "Infrastructure        RF                       0.926759          0.163883  \n",
       "                      KNN                      0.203016          0.049346  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by Train-Test and then C-V\n",
    "df.sort_values(by = ['train_test_score', 'opt_cv_score'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04efe2e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>train_train_score</th>\n",
       "      <th>train_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>110</td>\n",
       "      <td>0.137395</td>\n",
       "      <td>0.952604</td>\n",
       "      <td>0.898981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>100</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.955909</td>\n",
       "      <td>0.896342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>152</td>\n",
       "      <td>0.155647</td>\n",
       "      <td>0.953851</td>\n",
       "      <td>0.890687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>RF</th>\n",
       "      <td>156</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>0.959330</td>\n",
       "      <td>0.880351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 85% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.460020</td>\n",
       "      <td>0.753525</td>\n",
       "      <td>0.845075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 95% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>11</td>\n",
       "      <td>0.489815</td>\n",
       "      <td>0.751484</td>\n",
       "      <td>0.837076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 90% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>15</td>\n",
       "      <td>0.461747</td>\n",
       "      <td>0.728076</td>\n",
       "      <td>0.830863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA 80% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>17</td>\n",
       "      <td>0.444343</td>\n",
       "      <td>0.698082</td>\n",
       "      <td>0.830044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand</th>\n",
       "      <th>RF</th>\n",
       "      <td>106</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.950778</td>\n",
       "      <td>0.753863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Demographic</th>\n",
       "      <th>RF</th>\n",
       "      <td>128</td>\n",
       "      <td>0.493901</td>\n",
       "      <td>0.972145</td>\n",
       "      <td>0.704654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>14</td>\n",
       "      <td>0.369606</td>\n",
       "      <td>0.666974</td>\n",
       "      <td>0.655857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demand</th>\n",
       "      <th>KNN</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.242010</td>\n",
       "      <td>0.565045</td>\n",
       "      <td>0.530898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PCA 100% (All X Vars)</th>\n",
       "      <th>KNN</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.223305</td>\n",
       "      <td>0.284959</td>\n",
       "      <td>0.396555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>105</td>\n",
       "      <td>-0.609288</td>\n",
       "      <td>0.863086</td>\n",
       "      <td>0.276005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Infrastructure</th>\n",
       "      <th>RF</th>\n",
       "      <td>136</td>\n",
       "      <td>-0.645418</td>\n",
       "      <td>0.926759</td>\n",
       "      <td>0.163883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>76</td>\n",
       "      <td>-0.660480</td>\n",
       "      <td>0.203016</td>\n",
       "      <td>0.049346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      opt_hyperparam  opt_cv_score  \\\n",
       "model_num             model_approach                                 \n",
       "PCA 90% (All X Vars)  RF                         110      0.137395   \n",
       "PCA 85% (All X Vars)  RF                         100      0.133000   \n",
       "PCA 80% (All X Vars)  RF                         152      0.155647   \n",
       "PCA 95% (All X Vars)  RF                         156      0.076184   \n",
       "PCA 85% (All X Vars)  KNN                         11      0.460020   \n",
       "PCA 95% (All X Vars)  KNN                         11      0.489815   \n",
       "PCA 90% (All X Vars)  KNN                         15      0.461747   \n",
       "PCA 80% (All X Vars)  KNN                         17      0.444343   \n",
       "Demand                RF                         106      0.171865   \n",
       "Demographic           RF                         128      0.493901   \n",
       "                      KNN                         14      0.369606   \n",
       "Demand                KNN                         13     -0.242010   \n",
       "PCA 100% (All X Vars) KNN                         49     -0.223305   \n",
       "                      RF                         105     -0.609288   \n",
       "Infrastructure        RF                         136     -0.645418   \n",
       "                      KNN                         76     -0.660480   \n",
       "\n",
       "                                      train_train_score  train_test_score  \n",
       "model_num             model_approach                                       \n",
       "PCA 90% (All X Vars)  RF                       0.952604          0.898981  \n",
       "PCA 85% (All X Vars)  RF                       0.955909          0.896342  \n",
       "PCA 80% (All X Vars)  RF                       0.953851          0.890687  \n",
       "PCA 95% (All X Vars)  RF                       0.959330          0.880351  \n",
       "PCA 85% (All X Vars)  KNN                      0.753525          0.845075  \n",
       "PCA 95% (All X Vars)  KNN                      0.751484          0.837076  \n",
       "PCA 90% (All X Vars)  KNN                      0.728076          0.830863  \n",
       "PCA 80% (All X Vars)  KNN                      0.698082          0.830044  \n",
       "Demand                RF                       0.950778          0.753863  \n",
       "Demographic           RF                       0.972145          0.704654  \n",
       "                      KNN                      0.666974          0.655857  \n",
       "Demand                KNN                      0.565045          0.530898  \n",
       "PCA 100% (All X Vars) KNN                      0.284959          0.396555  \n",
       "                      RF                       0.863086          0.276005  \n",
       "Infrastructure        RF                       0.926759          0.163883  \n",
       "                      KNN                      0.203016          0.049346  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by Train-Test and then Train-Train\n",
    "df.sort_values(by = ['train_test_score', 'train_train_score'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7137a",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d538084",
   "metadata": {},
   "source": [
    "### Problem 2:\n",
    "\n",
    "Classification: Using the following dataset:\n",
    "https://www.kaggle.com/vikasukani/parkinsons-disease-data-set\n",
    "\n",
    "Create the **best classification model** you can using what we learned in class. Use any of the methods we explored and show how you **assessed how good your model is carefully. Using AUC is a good idea.** The **label variable is \"status\"**. \n",
    "\n",
    "The variables are as follows:\n",
    "- **name** - ASCII subject name and recording number\n",
    "- **MDVP:Fo(Hz)** - Average vocal fundamental frequency\n",
    "- **MDVP:Fhi(Hz)** - Maximum vocal fundamental frequency\n",
    "- **MDVP:Flo(Hz)** - Minimum vocal fundamental frequency\n",
    "- **MDVP:Jitter(%) , MDVP:Jitter(Abs) , MDVP:RAP , MDVP:PPQ , Jitter:DDP** - Several measures of variation in fundamental frequency\n",
    "- **MDVP:Shimmer , MDVP:Shimmer(dB) , Shimmer:APQ3 , Shimmer:APQ5 , MDVP:APQ , Shimmer:DDA** - Several measures of variation in amplitude\n",
    "- **NHR , HNR** - Two measures of ratio of noise to tonal components in the voice\n",
    "- **status** - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "- **RPDE , D2** - Two nonlinear dynamical complexity measures\n",
    "- **DFA** - Signal fractal scaling exponent\n",
    "- **spread1 , spread2 , PPE** - Three nonlinear measures of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f43b9",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e2187",
   "metadata": {},
   "source": [
    "As shared insightfully by the Professor during the recent lecture on ethics, a better understanding of the underlying context of a dataset—sometimes obtainable from experts in the field—could help us approach analyses more responsibly. Nonetheless, given the relatively limited scope and timeline of this assignment, and the lack of expertise in the field of biomedicine for all of us (as well as our colleagues and acquaintances), we have decided to postulate that the published dataset given for the purpose of this assignment, out of good faith, accurately illustrates relations that are of a correlation or association nature (we do not have enough information or expertise to determine any causal relation), between **attributes of \"biomedical voice measurements\"** and the **health status of suffering from Parkinson's disease (PD)**.\n",
    "\n",
    "With this underlying assumption, we will experiment with different classification models where the explanatory variables are combinations of different **attributes of \"biomedical voice measurements\"** (many measurements happen to be statistical properties of distributions, of which we do have some degree of knowledge and understanding), and assess/compare those models with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7f25a",
   "metadata": {},
   "source": [
    "But before any further experimentations, let us first take a look at the (raw) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98aa2523",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phon_R01_S01_6</td>\n",
       "      <td>120.552</td>\n",
       "      <td>131.162</td>\n",
       "      <td>113.787</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00463</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.01388</td>\n",
       "      <td>0.04701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06985</td>\n",
       "      <td>0.01222</td>\n",
       "      <td>21.378</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415564</td>\n",
       "      <td>0.825069</td>\n",
       "      <td>-4.242867</td>\n",
       "      <td>0.299111</td>\n",
       "      <td>2.187560</td>\n",
       "      <td>0.357775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phon_R01_S02_1</td>\n",
       "      <td>120.267</td>\n",
       "      <td>137.244</td>\n",
       "      <td>114.820</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02337</td>\n",
       "      <td>0.00607</td>\n",
       "      <td>24.886</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596040</td>\n",
       "      <td>0.764112</td>\n",
       "      <td>-5.634322</td>\n",
       "      <td>0.257682</td>\n",
       "      <td>1.854785</td>\n",
       "      <td>0.211756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>phon_R01_S02_2</td>\n",
       "      <td>107.332</td>\n",
       "      <td>113.840</td>\n",
       "      <td>104.315</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.00431</td>\n",
       "      <td>0.01567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02487</td>\n",
       "      <td>0.00344</td>\n",
       "      <td>26.892</td>\n",
       "      <td>1</td>\n",
       "      <td>0.637420</td>\n",
       "      <td>0.763262</td>\n",
       "      <td>-6.167603</td>\n",
       "      <td>0.183721</td>\n",
       "      <td>2.064693</td>\n",
       "      <td>0.163755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>phon_R01_S02_3</td>\n",
       "      <td>95.730</td>\n",
       "      <td>132.068</td>\n",
       "      <td>91.754</td>\n",
       "      <td>0.00551</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.00880</td>\n",
       "      <td>0.02093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03218</td>\n",
       "      <td>0.01070</td>\n",
       "      <td>21.812</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615551</td>\n",
       "      <td>0.773587</td>\n",
       "      <td>-5.498678</td>\n",
       "      <td>0.327769</td>\n",
       "      <td>2.322511</td>\n",
       "      <td>0.231571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phon_R01_S02_4</td>\n",
       "      <td>95.056</td>\n",
       "      <td>120.103</td>\n",
       "      <td>91.226</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.00803</td>\n",
       "      <td>0.02838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04324</td>\n",
       "      <td>0.01022</td>\n",
       "      <td>21.862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547037</td>\n",
       "      <td>0.798463</td>\n",
       "      <td>-5.011879</td>\n",
       "      <td>0.325996</td>\n",
       "      <td>2.432792</td>\n",
       "      <td>0.271362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phon_R01_S02_5</td>\n",
       "      <td>88.333</td>\n",
       "      <td>112.240</td>\n",
       "      <td>84.072</td>\n",
       "      <td>0.00505</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00254</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>0.00763</td>\n",
       "      <td>0.02143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.01166</td>\n",
       "      <td>21.118</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611137</td>\n",
       "      <td>0.776156</td>\n",
       "      <td>-5.249770</td>\n",
       "      <td>0.391002</td>\n",
       "      <td>2.407313</td>\n",
       "      <td>0.249740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phon_R01_S02_6</td>\n",
       "      <td>91.904</td>\n",
       "      <td>115.871</td>\n",
       "      <td>86.292</td>\n",
       "      <td>0.00540</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.00336</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>0.02752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04272</td>\n",
       "      <td>0.01141</td>\n",
       "      <td>21.414</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583390</td>\n",
       "      <td>0.792520</td>\n",
       "      <td>-4.960234</td>\n",
       "      <td>0.363566</td>\n",
       "      <td>2.642476</td>\n",
       "      <td>0.275931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>phon_R01_S04_1</td>\n",
       "      <td>136.926</td>\n",
       "      <td>159.866</td>\n",
       "      <td>131.276</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00118</td>\n",
       "      <td>0.00153</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.01259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>0.00581</td>\n",
       "      <td>25.703</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>-6.547148</td>\n",
       "      <td>0.152813</td>\n",
       "      <td>2.041277</td>\n",
       "      <td>0.138512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phon_R01_S04_2</td>\n",
       "      <td>139.173</td>\n",
       "      <td>179.139</td>\n",
       "      <td>76.556</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>0.00496</td>\n",
       "      <td>0.01642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02184</td>\n",
       "      <td>0.01041</td>\n",
       "      <td>24.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430166</td>\n",
       "      <td>0.665833</td>\n",
       "      <td>-5.660217</td>\n",
       "      <td>0.254989</td>\n",
       "      <td>2.519422</td>\n",
       "      <td>0.199889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>phon_R01_S04_3</td>\n",
       "      <td>152.845</td>\n",
       "      <td>163.305</td>\n",
       "      <td>75.836</td>\n",
       "      <td>0.00294</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.00149</td>\n",
       "      <td>0.00364</td>\n",
       "      <td>0.01828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03191</td>\n",
       "      <td>0.00609</td>\n",
       "      <td>24.922</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474791</td>\n",
       "      <td>0.654027</td>\n",
       "      <td>-6.105098</td>\n",
       "      <td>0.203653</td>\n",
       "      <td>2.125618</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>phon_R01_S04_4</td>\n",
       "      <td>142.167</td>\n",
       "      <td>217.455</td>\n",
       "      <td>83.159</td>\n",
       "      <td>0.00369</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00157</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.00471</td>\n",
       "      <td>0.01503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02316</td>\n",
       "      <td>0.00839</td>\n",
       "      <td>25.175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565924</td>\n",
       "      <td>0.658245</td>\n",
       "      <td>-5.340115</td>\n",
       "      <td>0.210185</td>\n",
       "      <td>2.205546</td>\n",
       "      <td>0.234589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>phon_R01_S04_5</td>\n",
       "      <td>144.188</td>\n",
       "      <td>349.259</td>\n",
       "      <td>82.764</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00211</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02908</td>\n",
       "      <td>0.01859</td>\n",
       "      <td>22.333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567380</td>\n",
       "      <td>0.644692</td>\n",
       "      <td>-5.440040</td>\n",
       "      <td>0.239764</td>\n",
       "      <td>2.264501</td>\n",
       "      <td>0.218164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>phon_R01_S04_6</td>\n",
       "      <td>168.778</td>\n",
       "      <td>232.181</td>\n",
       "      <td>75.603</td>\n",
       "      <td>0.00718</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00284</td>\n",
       "      <td>0.00387</td>\n",
       "      <td>0.00853</td>\n",
       "      <td>0.03327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04322</td>\n",
       "      <td>0.02919</td>\n",
       "      <td>20.376</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631099</td>\n",
       "      <td>0.605417</td>\n",
       "      <td>-2.931070</td>\n",
       "      <td>0.434326</td>\n",
       "      <td>3.007463</td>\n",
       "      <td>0.430788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>phon_R01_S05_1</td>\n",
       "      <td>153.046</td>\n",
       "      <td>175.829</td>\n",
       "      <td>68.623</td>\n",
       "      <td>0.00742</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00364</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.01092</td>\n",
       "      <td>0.05517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07413</td>\n",
       "      <td>0.03160</td>\n",
       "      <td>17.280</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665318</td>\n",
       "      <td>0.719467</td>\n",
       "      <td>-3.949079</td>\n",
       "      <td>0.357870</td>\n",
       "      <td>3.109010</td>\n",
       "      <td>0.377429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>phon_R01_S05_2</td>\n",
       "      <td>156.405</td>\n",
       "      <td>189.398</td>\n",
       "      <td>142.822</td>\n",
       "      <td>0.00768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00372</td>\n",
       "      <td>0.00399</td>\n",
       "      <td>0.01116</td>\n",
       "      <td>0.03995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05164</td>\n",
       "      <td>0.03365</td>\n",
       "      <td>17.153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.649554</td>\n",
       "      <td>0.686080</td>\n",
       "      <td>-4.554466</td>\n",
       "      <td>0.340176</td>\n",
       "      <td>2.856676</td>\n",
       "      <td>0.322111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0   phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1   phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2   phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3   phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4   phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "5   phon_R01_S01_6      120.552       131.162       113.787         0.00968   \n",
       "6   phon_R01_S02_1      120.267       137.244       114.820         0.00333   \n",
       "7   phon_R01_S02_2      107.332       113.840       104.315         0.00290   \n",
       "8   phon_R01_S02_3       95.730       132.068        91.754         0.00551   \n",
       "9   phon_R01_S02_4       95.056       120.103        91.226         0.00532   \n",
       "10  phon_R01_S02_5       88.333       112.240        84.072         0.00505   \n",
       "11  phon_R01_S02_6       91.904       115.871        86.292         0.00540   \n",
       "12  phon_R01_S04_1      136.926       159.866       131.276         0.00293   \n",
       "13  phon_R01_S04_2      139.173       179.139        76.556         0.00390   \n",
       "14  phon_R01_S04_3      152.845       163.305        75.836         0.00294   \n",
       "15  phon_R01_S04_4      142.167       217.455        83.159         0.00369   \n",
       "16  phon_R01_S04_5      144.188       349.259        82.764         0.00544   \n",
       "17  phon_R01_S04_6      168.778       232.181        75.603         0.00718   \n",
       "18  phon_R01_S05_1      153.046       175.829        68.623         0.00742   \n",
       "19  phon_R01_S05_2      156.405       189.398       142.822         0.00768   \n",
       "\n",
       "    MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0            0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1            0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2            0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3            0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4            0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "5            0.00008   0.00463   0.00750     0.01388       0.04701  ...   \n",
       "6            0.00003   0.00155   0.00202     0.00466       0.01608  ...   \n",
       "7            0.00003   0.00144   0.00182     0.00431       0.01567  ...   \n",
       "8            0.00006   0.00293   0.00332     0.00880       0.02093  ...   \n",
       "9            0.00006   0.00268   0.00332     0.00803       0.02838  ...   \n",
       "10           0.00006   0.00254   0.00330     0.00763       0.02143  ...   \n",
       "11           0.00006   0.00281   0.00336     0.00844       0.02752  ...   \n",
       "12           0.00002   0.00118   0.00153     0.00355       0.01259  ...   \n",
       "13           0.00003   0.00165   0.00208     0.00496       0.01642  ...   \n",
       "14           0.00002   0.00121   0.00149     0.00364       0.01828  ...   \n",
       "15           0.00003   0.00157   0.00203     0.00471       0.01503  ...   \n",
       "16           0.00004   0.00211   0.00292     0.00632       0.02047  ...   \n",
       "17           0.00004   0.00284   0.00387     0.00853       0.03327  ...   \n",
       "18           0.00005   0.00364   0.00432     0.01092       0.05517  ...   \n",
       "19           0.00005   0.00372   0.00399     0.01116       0.03995  ...   \n",
       "\n",
       "    Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0       0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1       0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2       0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3       0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4       0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "5       0.06985  0.01222  21.378       1  0.415564  0.825069 -4.242867   \n",
       "6       0.02337  0.00607  24.886       1  0.596040  0.764112 -5.634322   \n",
       "7       0.02487  0.00344  26.892       1  0.637420  0.763262 -6.167603   \n",
       "8       0.03218  0.01070  21.812       1  0.615551  0.773587 -5.498678   \n",
       "9       0.04324  0.01022  21.862       1  0.547037  0.798463 -5.011879   \n",
       "10      0.03237  0.01166  21.118       1  0.611137  0.776156 -5.249770   \n",
       "11      0.04272  0.01141  21.414       1  0.583390  0.792520 -4.960234   \n",
       "12      0.01968  0.00581  25.703       1  0.460600  0.646846 -6.547148   \n",
       "13      0.02184  0.01041  24.889       1  0.430166  0.665833 -5.660217   \n",
       "14      0.03191  0.00609  24.922       1  0.474791  0.654027 -6.105098   \n",
       "15      0.02316  0.00839  25.175       1  0.565924  0.658245 -5.340115   \n",
       "16      0.02908  0.01859  22.333       1  0.567380  0.644692 -5.440040   \n",
       "17      0.04322  0.02919  20.376       1  0.631099  0.605417 -2.931070   \n",
       "18      0.07413  0.03160  17.280       1  0.665318  0.719467 -3.949079   \n",
       "19      0.05164  0.03365  17.153       1  0.649554  0.686080 -4.554466   \n",
       "\n",
       "     spread2        D2       PPE  \n",
       "0   0.266482  2.301442  0.284654  \n",
       "1   0.335590  2.486855  0.368674  \n",
       "2   0.311173  2.342259  0.332634  \n",
       "3   0.334147  2.405554  0.368975  \n",
       "4   0.234513  2.332180  0.410335  \n",
       "5   0.299111  2.187560  0.357775  \n",
       "6   0.257682  1.854785  0.211756  \n",
       "7   0.183721  2.064693  0.163755  \n",
       "8   0.327769  2.322511  0.231571  \n",
       "9   0.325996  2.432792  0.271362  \n",
       "10  0.391002  2.407313  0.249740  \n",
       "11  0.363566  2.642476  0.275931  \n",
       "12  0.152813  2.041277  0.138512  \n",
       "13  0.254989  2.519422  0.199889  \n",
       "14  0.203653  2.125618  0.170100  \n",
       "15  0.210185  2.205546  0.234589  \n",
       "16  0.239764  2.264501  0.218164  \n",
       "17  0.434326  3.007463  0.430788  \n",
       "18  0.357870  3.109010  0.377429  \n",
       "19  0.340176  2.856676  0.322111  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2 = pd.read_csv('parkinsons.data')\n",
    "df_p2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8521feec",
   "metadata": {},
   "source": [
    "What about the dimension (number of rows and columns) and data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af315d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 24)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84d0073e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                 object\n",
       "MDVP:Fo(Hz)         float64\n",
       "MDVP:Fhi(Hz)        float64\n",
       "MDVP:Flo(Hz)        float64\n",
       "MDVP:Jitter(%)      float64\n",
       "MDVP:Jitter(Abs)    float64\n",
       "MDVP:RAP            float64\n",
       "MDVP:PPQ            float64\n",
       "Jitter:DDP          float64\n",
       "MDVP:Shimmer        float64\n",
       "MDVP:Shimmer(dB)    float64\n",
       "Shimmer:APQ3        float64\n",
       "Shimmer:APQ5        float64\n",
       "MDVP:APQ            float64\n",
       "Shimmer:DDA         float64\n",
       "NHR                 float64\n",
       "HNR                 float64\n",
       "status                int64\n",
       "RPDE                float64\n",
       "DFA                 float64\n",
       "spread1             float64\n",
       "spread2             float64\n",
       "D2                  float64\n",
       "PPE                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504fee8",
   "metadata": {},
   "source": [
    "Following our approach above, let us also graph histograms (overlaid with KDE estimation line) for each of our column variables for this second question. None of the variables suffer from significant outliers (in terms of distribution percentile or relative value). Feel free to go to our `\"p_2_hist\"` subdirectory to check out the histogram for each of the column variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1be76933",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_x_label in df_p2.columns:\n",
    "    obj = (ggplot(df_p2.dropna(subset = [var_x_label]), aes(x = var_x_label)) \n",
    "           + geom_histogram(aes(y = \"stat(density)\"), alpha = 0.5, fill = \"green\")\n",
    "           + geom_density(color = \"red\", alpha = 0.5)\n",
    "           + ggtitle('Histogram for the Density Distribution of \"{}\" with KDE Line'\\\n",
    "                     .format(var_x_label))\n",
    "           + ylab(\"Density\")\n",
    "           + xlab(var_x_label)\n",
    "           + theme_bw())\n",
    "    \n",
    "    obj.save(\"p_2_hist/hist_{name}.png\".format(name = var_x_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce0355",
   "metadata": {},
   "source": [
    "Great! It appears that the Pandas library has successfully recognized that all the column variables are, in fact, numeric measures. \n",
    "\n",
    "Considering that we will be dealing with a **classification problem** (rather than clustering, because we are assigning individual observations to a known, existing label), let us also check how balanced the two categories (classified under the label of *Parkinson's disease (PD)* (1) or otherwise *healthy* (0)) are in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd636bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    147\n",
       "0     48\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2['status'].value_counts() # NOTE: data imbalance; size up, likely "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19ce51",
   "metadata": {},
   "source": [
    "Oh no...! The **healthy** group is significantly **underrepresented** in the dataset, which can cause problems if we directly feed this imbalanced dataset into a classification model. Considering that we may need as many observations as possible for a more generalizable and representative model, let us proceed by **sizing up** the underrepresented *healthy* group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dfeb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstly, split the two groups \n",
    "df_PD = df_p2[df_p2['status'] == 1] # PD group (majority)\n",
    "df_healthy = df_p2[df_p2['status'] == 0] # healthy group (minority)\n",
    "\n",
    "df_healthy_up = resample(df_healthy,\n",
    "                         replace = True, # sample with replacement (we allow the repetition of row multiple times)\n",
    "                         n_samples = 147, # target size = size of majority (PD group)\n",
    "                         random_state = 0) # set random seed, for replicability \n",
    "\n",
    "df_p2_balanced = pd.concat([df_PD, df_healthy_up]) # create balanced df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8a5121f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    147\n",
       "0    147\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p2_balanced['status'].value_counts()\n",
    "# we can see that the two categories are now balanced (yay!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96fa00b",
   "metadata": {},
   "source": [
    "### A Brief Overview of Our Experimentation Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84632760",
   "metadata": {},
   "source": [
    "We are now in a good shape to proceed with our experimentation with different prediction models (based on different underlying theoretical assumptions). Now, for each model, we will experiment with **three classification methods/approaches**:\n",
    "- **K-Nearest Neighbors Classifier (KNNC)**, where we will also find the optimal hyperparameter for the number of neighbors (`n_neighbors`)\n",
    "- **Random Forest Classifier (RFC)**, where we will also find the optimal hyperparameter for the number of estimators (`n_estimators`)\n",
    "- **Logistic Regression**, which *does not* have a hyperparameter, according to the Professor.\n",
    "\n",
    "Thus, the **algorithm steps** for each model (based on theory) and approach (based on methodology) will be as follows:\n",
    "1. Find the **optimal hyperparameter** for the approach using **cross-validation (CV)** if applicable. We use the CV approach to make sure that the optimal value is indeed **generalizable** across different train-test split combinations. \n",
    "2. Report the **optimal hyperparameter and the optimal CV score** if applicable. \n",
    "3. Conduct a **specific instance of random train-test split** (using `random_state = 0`, for replicability). \n",
    "4. Report the **classification report and ROC-AUC score** for the **test data** of the train-test split (note that we will not fit the model and then predict using the *entire* dataset, to *avoid overfitting*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c0805",
   "metadata": {},
   "source": [
    "For each experiment, we will also record the relevant model/approach name and scores for comparison later. And, after conducting these steps for each of our models and approaches, we will rank, from highest to lowest, the **CV score and ROC-AUC score** (in order of priority, using sorting by multiple indices) of all the experiments. \n",
    "\n",
    "The model that performs the best in terms of those measures across all three classification methods/approaches will be our optimal model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052527da",
   "metadata": {},
   "source": [
    "Let us begin this fun journey of model experimentation! May you share the thrill with us along the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5f877",
   "metadata": {},
   "source": [
    "### Problem 2, Model 1: Using the *Frequency* of Voice to Explain Classification of PD\n",
    "We shall use the following variables as explanatory variables\n",
    "- **MDVP:Fo(Hz) - Average vocal fundamental frequency.** This controls for the distribution of the vocal fundamental frequency (average/mean value).\n",
    "- **MDVP:Fhi(Hz) - Maximum vocal fundamental frequency.** This controls for the distribution of the vocal fundamental frequency (maximum end of interval).\n",
    "- **MDVP:Flo(Hz) - Minimum vocal fundamental frequency.** This controls for the distribution of the vocal fundamental frequency (minimum end of interval).\n",
    "- **MDVP:Jitter(%), MDVP:Jitter(Abs), MDVP:RAP, MDVP:PPQ, Jitter:DDP - Several measures of variation in fundamental frequency.** This controls for the variation of the distribution of the vocal fundamental frequency.\n",
    "- **NHR, HNR - Two measures of the ratio of noise to tonal components in the voice.** This controls for any voice component that is of an idiosyncratic (random noise) nature. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c7570",
   "metadata": {},
   "source": [
    "#### Using the KNNC Method\n",
    "In the same spirit as the KNN method, where proximity (\"neighboring\") is determined based on the Euclidean distance metric, we will start with the KNNC method—except that the outcome variable is the likelihood that an individual observation could belong to either category. Let us directly proceed with trying to find the **optimal hyperparameter** for the number of neighbors `n_neighbors` using cross-validation (for more general applicability):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c002ae85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>num_neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  num_neighbors\n",
       "0  0.898188              1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using knnc, as we are *classifying* the ind. obs.\n",
    "\n",
    "# experiment with the hyperparameter (n_neighbors) from 1 to 100\n",
    "score_array = [cross_val_score(knnc(n_neighbors = i), \n",
    "                               X = df_p2_balanced[['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "                                                   'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "                                                   'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "                                                   'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR']], \n",
    "                               y = df_p2_balanced['status'], cv = 5).mean() for i in range(1, 101, 1)]\n",
    "\n",
    "# construct the df to record the score and corresponding hyperparameter (n_neighbors)\n",
    "cv_df = pd.DataFrame(score_array, columns = ['score'])\n",
    "cv_df['num_neighbors'] = list(range(1, 101, 1))\n",
    "\n",
    "# let us find the entry with the maximum cv score\n",
    "# and the corresponding num_neighbors (K)\n",
    "cv_df.loc[cv_df['score'] == cv_df['score'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efd834",
   "metadata": {},
   "source": [
    "Great! We have found that the **optimal hyperparameter** for the number of neighbors `n_neighbors` using cross-validation is **1**. \n",
    "\n",
    "Let us proceed by creating a **specific random train-test split instance (using `random_state = 0`)** and look at its classification report, as well as its ROC-AUC score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a83a5e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9615384615384616"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle and split training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_p2_balanced[['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "                                                         'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "                                                         'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "                                                         'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR']], \n",
    "                                                    df_p2_balanced['status'], \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0) # using the same random state that is 0\n",
    "\n",
    "# use the optimal hyperparameter, fit the train data, predict using the test (\"never-seen-before\") data\n",
    "Y_test_predict = knnc(n_neighbors = 1).fit(X_train, Y_train).predict(X_test)\n",
    "Y_test_proba = knnc(n_neighbors = 1).fit(X_train, Y_train).predict_proba(X_test)\n",
    "\n",
    "roc_auc_score(y_true = Y_test, \n",
    "              y_score = Y_test_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b7e1b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.92      0.96        26\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred = Y_test_predict,\n",
    "                            y_true = Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402e07b",
   "metadata": {},
   "source": [
    "We want a ROC-AUC score **as close to 1 as possible**, so that we can increase the True Positive Rate (TPR), without also increasing the False Positive Rate (FPR), which we would want to minimize. A **ROC-AUC score** of approximately **0.9615** (train-test split using `random_state = 0`) is already quite good, but let us also experiment with other approaches and models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef106a5",
   "metadata": {},
   "source": [
    "#### Defining A Customized Function for the KNNC Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b435991",
   "metadata": {},
   "source": [
    "Actually, before anything else, in order to avoid repetition in typing the same lines of code over and over, let us define functions for each approach and model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "123f08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_approach_recs = [] # also, a container \n",
    "# to keep track of all the records of experiments with \n",
    "# different models and approaches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f08d9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnc_predict(model_num, df, var_labels, y_label, num_cv = 5, \n",
    "                 min_param = 1, max_param = 101, inc_param = 1, \n",
    "                 use_df = True, x_obj = None):\n",
    "    '''\n",
    "    (c) Brandon Gao (bsg9679), Siegrid Tuttle (sgt2559), and Michael Xu (tx542)\n",
    "    Data Bootcamp | Fall 2021 | NYU Stern\n",
    "    \n",
    "    -------------------------------------------------------------------------------------\n",
    "    \n",
    "    This function takes in the parameters:\n",
    "    - the model number (ordinal), and\n",
    "    - a Pandas DataFrame (`df`), and \n",
    "    - a list-like/iterable container object (`var_labels`) listing the \n",
    "    column labels that shall be used as the explanatory variable, and \n",
    "    - a column label that is the explained variable (y variable/label), and\n",
    "    - a customizable number of cross-validation groups (default is 5), and\n",
    "    - a customizable range to find the optimal hyperparameter, where\n",
    "        - min_param is the lower bound,\n",
    "        - max_param is the upper bound (not inclusive),\n",
    "        - inc_param is the increment\n",
    "        \n",
    "    Note: list of x will be obtained from the given df only if use_df is True\n",
    "    \n",
    "    It will then use the KNNC approach, with the optimal hyperparameter \n",
    "    (n_neighbors) within the range of [1, 100] (default) that has the maximum\n",
    "    cross-validation score, to construct the optimal KNNC classifier object.\n",
    "    \n",
    "    It will then conduct a random train-test split, and\n",
    "    print the classification_report and the ROC-AUC score.\n",
    "    \n",
    "    * Note that all random_state is 0, for the purpose of replicability.\n",
    "    '''\n",
    "    \n",
    "    # some user input checks...\n",
    "    \n",
    "    # DataFrame data type\n",
    "    if (type(df) != pd.core.frame.DataFrame):\n",
    "        print('Dataset is not a Pandas DataFrame object!')\n",
    "        return None\n",
    "    \n",
    "    # checks for the existence of x labels\n",
    "    if [(item in df.columns) for item in var_labels].count(True)\\\n",
    "    < len(var_labels) and use_df:\n",
    "        print('Not all explanatory variables are in the given DataFrame!')\n",
    "        return None\n",
    "        \n",
    "    # and also for the y label \n",
    "    if (type(y_label) != str) or (y_label not in df.columns):\n",
    "        print('Invalid y label!')\n",
    "        return None\n",
    "    \n",
    "    # also for the num_cv optional input\n",
    "    if (type(num_cv) != int):\n",
    "        print('Invalid CV number! Function will proceed with the default value, 5.')\n",
    "        num_cv = 5\n",
    "        \n",
    "    # determine whether index by labels or use list of x passed into the function\n",
    "    if not use_df:\n",
    "        X_VARS = x_obj\n",
    "    else:\n",
    "        X_VARS = df[var_labels]\n",
    "    \n",
    "    # --->>> experiment with the hyperparameter (n_neighbors) from 1 to 100 <<<---\n",
    "    score_array = [cross_val_score(knnc(n_neighbors = i), \n",
    "                                   X = X_VARS, \n",
    "                                   y = df[y_label], \n",
    "                                   cv = num_cv).mean() for i \\\n",
    "                   in range(min_param, max_param, inc_param)]\n",
    "\n",
    "    # construct the df to record the score and corresponding hyperparameter (n_neighbors)\n",
    "    cv_df = pd.DataFrame(score_array, columns = ['score'])\n",
    "    cv_df['num_neighbors'] = list(range(min_param, max_param, inc_param))\n",
    "\n",
    "    # let us find the entry with the maximum cv score\n",
    "    # and the corresponding num_neighbors (K)\n",
    "    opt_obs = cv_df.loc[cv_df['score'] == cv_df['score'].max()]\n",
    "    opt_param = int(opt_obs['num_neighbors'].iloc[0, ])\n",
    "    # take the first optimal parameter, in case that there are multiple\n",
    "    \n",
    "    # report the optimal hyperparameter and CV score:\n",
    "    print(\"The optimal hyperparameter is: {}.\\nAnd the optimal CV score is: {:.4f}.\\n\".\\\n",
    "         format(opt_param, float(opt_obs['score'].iloc[0, ])))\n",
    "    \n",
    "    # --->>> make the optimal prediction, using a train-test split <<<--- \n",
    "    # shuffle and split training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_VARS, \n",
    "                                                        df[y_label], \n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state = 0)\n",
    "\n",
    "    # use the optimal hyperparameter, fit the train data, predict using the test (\"never-seen-before\") data\n",
    "    Y_test_predict = knnc(n_neighbors = opt_param).fit(X_train, Y_train).predict(X_test)\n",
    "    Y_test_proba = knnc(n_neighbors = opt_param).fit(X_train, Y_train).predict_proba(X_test)\n",
    "    \n",
    "    # --->>> print the classification report, based on a random train-test split  <<<---\n",
    "    \n",
    "    print('''Using the KNNC Approach, \n",
    "Based on a random train-test split (using random_state = 0):''')\n",
    "    print(\"The classification report for the test data is:\\n\")\n",
    "    print(classification_report(y_pred = Y_test_predict,\n",
    "                                y_true = Y_test))\n",
    "    \n",
    "    # --->>> ROC-AUC score, based on a random train-test split <<<---\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true = Y_test, \n",
    "                            y_score = Y_test_proba[:, 1])\n",
    "    \n",
    "    print(\"And the ROC-AUC score for the test data is {:.4f}.\\n\".\\\n",
    "          format(roc_auc))\n",
    "\n",
    "    return {'model_num': model_num,\n",
    "            'model_approach': 'KNNC',\n",
    "            'opt_hyperparam': opt_param,\n",
    "            'opt_cv_score': float(opt_obs['score'].iloc[0, ]),\n",
    "            'roc_auc': roc_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e39a4",
   "metadata": {},
   "source": [
    "Let's see how our overall KNNC classification-prediction function works (whether it yields the same result as our previous separate cells/sections of codes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d644267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.8982.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.92      0.96        26\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9615.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this may take a while to run...\n",
    "all_model_approach_recs.append(knnc_predict(1, df_p2_balanced,\n",
    "             ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "              'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "              'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "              'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR'],\n",
    "             'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff250e88",
   "metadata": {},
   "source": [
    "Yay! Everything worked just as expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcfb6f4",
   "metadata": {},
   "source": [
    "#### Using the Random Forest Classifier Method and the Logistic Regression Method\n",
    "Also defining the respective **customized functions**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71bdcd",
   "metadata": {},
   "source": [
    "Let us also build the same functions for the **Random Forest Classifier** and **Logistic Regression** (which does not require any hyperparameter, according to the Professor) approaches, and then fit our Model 1 (using its list of theoretical explanatory variables to explain `status`) using both functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66d5cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_predict(model_num, df, var_labels, y_label, num_cv = 5, \n",
    "               min_param = 100, max_param = 201, inc_param = 1, \n",
    "               use_df = True, x_obj = None):\n",
    "    '''\n",
    "    (c) Brandon Gao (bsg9679), Siegrid Tuttle (sgt2559), and Michael Xu (tx542)\n",
    "    Data Bootcamp | Fall 2021 | NYU Stern\n",
    "    \n",
    "    -------------------------------------------------------------------------------------\n",
    "    \n",
    "    This function takes in the parameters:\n",
    "    - the model number (ordinal), and\n",
    "    - a Pandas DataFrame (`df`), and \n",
    "    - a list-like/iterable container object (`var_labels`) listing the \n",
    "    column labels that shall be used as the explanatory variable, and \n",
    "    - a column label that is the explained variable (y variable/label), and\n",
    "    - a customizable number of cross-validation groups (default is 5), and\n",
    "    - a customizable range to find the optimal hyperparameter, where\n",
    "        - min_param is the lower bound,\n",
    "        - max_param is the upper bound (not inclusive),\n",
    "        - inc_param is the increment\n",
    "        \n",
    "    Note: list of x will be obtained from the given df only if use_df is True\n",
    "    \n",
    "    It will then use the Random Forest Classifier approach, \n",
    "    with the optimal hyperparameter (number of estimators) within\n",
    "    the range of [100, 200] (default) that has the maximum\n",
    "    cross-validation score, to construct the optimal PFC classifier object.\n",
    "    \n",
    "    It will then conduct a random train-test split, and\n",
    "    print the classification_report and the ROC-AUC score.\n",
    "    \n",
    "    * Note that all random_state is 0, for the purpose of replicability.\n",
    "    '''\n",
    "    \n",
    "    # some user input checks...\n",
    "    \n",
    "    # DataFrame data type\n",
    "    if (type(df) != pd.core.frame.DataFrame):\n",
    "        print('Dataset is not a Pandas DataFrame object!')\n",
    "        return None\n",
    "    \n",
    "    # checks for the existence of x labels\n",
    "    if [(item in df.columns) for item in var_labels].count(True)\\\n",
    "    < len(var_labels) and use_df:\n",
    "        print('Not all explanatory variables are in the given DataFrame!')\n",
    "        return None\n",
    "        \n",
    "    # and also for the y label \n",
    "    if (type(y_label) != str) or (y_label not in df.columns):\n",
    "        print('Invalid y label!')\n",
    "        return None\n",
    "    \n",
    "    # also for the num_cv optional input\n",
    "    if (type(num_cv) != int):\n",
    "        print('Invalid CV number! Function will proceed with the default value, 5.')\n",
    "        num_cv = 5\n",
    "        \n",
    "    # determine whether index by labels or use list of x passed into the function\n",
    "    if not use_df:\n",
    "        X_VARS = x_obj\n",
    "    else:\n",
    "        X_VARS = df[var_labels]\n",
    "    \n",
    "    # --->>> experiment with the hyperparameter (number of estimators), from 5 to 200 <<<---\n",
    "    score_array = [cross_val_score(rf_clf(n_estimators = i), \n",
    "                                   X = X_VARS, \n",
    "                                   y = df[y_label], \n",
    "                                   cv = num_cv).mean() for i \\\n",
    "                   in range(min_param, max_param, inc_param)]\n",
    "\n",
    "    # construct the df to record the score and corresponding hyperparameter (n_estimators)\n",
    "    cv_df = pd.DataFrame(score_array, columns = ['score'])\n",
    "    cv_df['num_trees'] = list(range(min_param, max_param, inc_param))\n",
    "\n",
    "    # let us find the entry with the maximum cv score\n",
    "    # and the corresponding n_estimators\n",
    "    opt_obs = cv_df.loc[cv_df['score'] == cv_df['score'].max()]\n",
    "    opt_param = int(opt_obs['num_trees'].iloc[0, ])\n",
    "    # take the first optimal parameter, in case that there are multiple\n",
    "    \n",
    "    # report the optimal hyperparameter and CV score:\n",
    "    print(\"The optimal hyperparameter is: {}.\\nAnd the optimal CV score is: {:.4f}.\\n\".\\\n",
    "         format(opt_param, float(opt_obs['score'].iloc[0, ])))\n",
    "    \n",
    "    # --->>> make the optimal prediction, using a train-test split <<<--- \n",
    "    # shuffle and split training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_VARS, \n",
    "                                                        df[y_label], \n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state = 0)\n",
    "\n",
    "    # use the optimal hyperparameter, fit the train data, predict using the test (\"never-seen-before\") data\n",
    "    Y_test_predict = rf_clf(n_estimators = opt_param).fit(X_train, Y_train).predict(X_test)\n",
    "    Y_test_proba = rf_clf(n_estimators = opt_param).fit(X_train, Y_train).predict_proba(X_test)\n",
    "    \n",
    "    # --->>> print the classification report, based on a random train-test split  <<<---\n",
    "    \n",
    "    print('''Using the Random Forest Classifier Approach, \n",
    "Based on a random train-test split (using random_state = 0):''')\n",
    "    print(\"The classification report for the test data is:\\n\")\n",
    "    print(classification_report(y_pred = Y_test_predict,\n",
    "                                y_true = Y_test))\n",
    "    \n",
    "    # --->>> ROC-AUC score, based on a random train-test split <<<---\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true = Y_test, \n",
    "                            y_score = Y_test_proba[:, 1])\n",
    "    \n",
    "    print(\"And the ROC-AUC score for the test data is {:.4f}.\\n\".\\\n",
    "          format(roc_auc))\n",
    "\n",
    "    return {'model_num': model_num,\n",
    "            'model_approach': 'RFC',\n",
    "            'opt_hyperparam': opt_param,\n",
    "            'opt_cv_score': float(opt_obs['score'].iloc[0, ]),\n",
    "            'roc_auc': roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4418405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal hyperparameter is: 131.\n",
      "And the optimal CV score is: 0.9525.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.92      0.96        26\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9977.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this may take a while to run (longer than the KNNC approach)...\n",
    "all_model_approach_recs.append(rf_predict(1, df_p2_balanced,\n",
    "           ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "            'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "            'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "            'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR'],\n",
    "           'status'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "909220b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_predict(model_num, df, var_labels, y_label, num_cv = 5, \n",
    "                     use_df = True, x_obj = None):\n",
    "    '''\n",
    "    (c) Brandon Gao (bsg9679), Siegrid Tuttle (sgt2559), and Michael Xu (tx542)\n",
    "    Data Bootcamp | Fall 2021 | NYU Stern\n",
    "    \n",
    "    -------------------------------------------------------------------------------------\n",
    "    \n",
    "    This function takes in the parameters:\n",
    "    - the model number (ordinal), and\n",
    "    - a Pandas DataFrame (`df`), and \n",
    "    - a list-like/iterable container object (`var_labels`) listing the \n",
    "    column labels that shall be used as the explanatory variable, and \n",
    "    - a column label that is the explained variable (y variable/label), and\n",
    "    - a customizable number of cross-validation groups (default is 5)\n",
    "    \n",
    "    Note: list of x will be obtained from the given df only if use_df is True\n",
    "    \n",
    "    It will then use the Logistic Regression approach, report the \n",
    "    cross-validation score, and then construct the classifier object.\n",
    "    \n",
    "    It will then conduct a random train-test split, and\n",
    "    print the classification_report and the ROC-AUC score.\n",
    "    \n",
    "    * Note that all random_state is 0, for the purpose of replicability.\n",
    "    '''\n",
    "    \n",
    "    # some user input checks...\n",
    "    \n",
    "    # DataFrame data type\n",
    "    if (type(df) != pd.core.frame.DataFrame):\n",
    "        print('Dataset is not a Pandas DataFrame object!')\n",
    "        return None\n",
    "    \n",
    "    # checks for the existence of x labels\n",
    "    if [(item in df.columns) for item in var_labels].count(True)\\\n",
    "    < len(var_labels) and use_df:\n",
    "        print('Not all explanatory variables are in the given DataFrame!')\n",
    "        return None\n",
    "        \n",
    "    # and also for the y label \n",
    "    if (type(y_label) != str) or (y_label not in df.columns):\n",
    "        print('Invalid y label!')\n",
    "        return None\n",
    "    \n",
    "    # also for the num_cv optional input\n",
    "    if (type(num_cv) != int):\n",
    "        print('Invalid CV number! Function will proceed with the default value, 5.')\n",
    "        num_cv = 5\n",
    "        \n",
    "    # determine whether index by labels or use list of x passed into the function\n",
    "    if not use_df:\n",
    "        X_VARS = x_obj\n",
    "    else:\n",
    "        X_VARS = df[var_labels]\n",
    "        \n",
    "    # report the CV score:\n",
    "    cv_score = cross_val_score(LogisticRegression(), \n",
    "                               X = X_VARS,\n",
    "                               y = df[y_label], \n",
    "                               cv = num_cv).mean()\n",
    "    \n",
    "    print(\"The CV score is: {:.4f}.\\n\".format(cv_score))\n",
    "    \n",
    "    # --->>> make the prediction, using a train-test split <<<--- \n",
    "    # shuffle and split training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_VARS, \n",
    "                                                        df[y_label], \n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state = 0)\n",
    "\n",
    "    # fit the train data, predict using the test (\"never-seen-before\") data\n",
    "    Y_test_predict = LogisticRegression().fit(X_train, Y_train).predict(X_test)\n",
    "    Y_test_proba = LogisticRegression().fit(X_train, Y_train).predict_proba(X_test)\n",
    "    \n",
    "    # --->>> print the classification report, based on a random train-test split  <<<---\n",
    "    \n",
    "    print('''Using the Logistic Regression Approach, \n",
    "Based on a random train-test split (using random_state = 0):''')\n",
    "    print(\"The classification report for the test data is:\\n\")\n",
    "    print(classification_report(y_pred = Y_test_predict,\n",
    "                                y_true = Y_test))\n",
    "    \n",
    "    # --->>> ROC-AUC score, based on a random train-test split <<<---\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true = Y_test, \n",
    "                            y_score = Y_test_proba[:, 1])\n",
    "    \n",
    "    print(\"And the ROC-AUC score for the test data is {:.4f}.\\n\".\\\n",
    "          format(roc_auc))\n",
    "\n",
    "    return {'model_num': model_num,\n",
    "            'model_approach': 'LogR',\n",
    "            'opt_hyperparam': np.NaN,\n",
    "            'opt_cv_score': cv_score,\n",
    "            'roc_auc': roc_auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90bfef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV score is: 0.7009.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.75        33\n",
      "           1       0.68      0.81      0.74        26\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.75      0.75      0.75        59\n",
      "weighted avg       0.76      0.75      0.75        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8543.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this should run very quickly (no need to find optimal hyperparameter)\n",
    "all_model_approach_recs.append(logistic_predict(1, df_p2_balanced,\n",
    "                 ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "                  'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "                  'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "                  'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR'],\n",
    "                 'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74709f89",
   "metadata": {},
   "source": [
    "### Problem 2, Model 2: Using the *Amplitude* of Voice to Explain Classification of PD\n",
    "We shall use the following as explanatory variables\n",
    "\n",
    "- **MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude.** These can control for the variation of the amplitude of the voice (a different measure from the frequency).\n",
    "- **NHR, HNR - Two measures of the ratio of noise to tonal components in the voice.** This controls for any voice component that is of an idiosyncratic (random noise) nature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648bd15f",
   "metadata": {},
   "source": [
    "#### Using the KNNC Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c91b51ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.8775.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        33\n",
      "           1       1.00      0.81      0.89        26\n",
      "\n",
      "    accuracy                           0.92        59\n",
      "   macro avg       0.93      0.90      0.91        59\n",
      "weighted avg       0.93      0.92      0.91        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9038.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this may take a while to run...\n",
    "all_model_approach_recs.append(knnc_predict(2, df_p2_balanced,\n",
    "             ['MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', \n",
    "              'Shimmer:APQ5','MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR'],\n",
    "             'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3c840",
   "metadata": {},
   "source": [
    "#### Using the Random Forest Classifier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aacb69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal hyperparameter is: 149.\n",
      "And the optimal CV score is: 0.8981.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        33\n",
      "           1       1.00      0.77      0.87        26\n",
      "\n",
      "    accuracy                           0.90        59\n",
      "   macro avg       0.92      0.88      0.89        59\n",
      "weighted avg       0.91      0.90      0.90        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9959.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this may take a while to run (longer than the KNNC approach)...\n",
    "all_model_approach_recs.append(rf_predict(2, df_p2_balanced,\n",
    "           ['MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', \n",
    "            'Shimmer:APQ5','MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR'],\n",
    "           'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6bf21c",
   "metadata": {},
   "source": [
    "#### Using the Logistic Regression Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cab0808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV score is: 0.7554.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        33\n",
      "           1       0.74      0.77      0.75        26\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.78      0.78      0.78        59\n",
      "weighted avg       0.78      0.78      0.78        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8298.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this should run very quickly (no need to find optimal hyperparameter)\n",
    "all_model_approach_recs.append(logistic_predict(2, df_p2_balanced,\n",
    "                 ['MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', \n",
    "                  'Shimmer:APQ5','MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR'],\n",
    "                 'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0e4758",
   "metadata": {},
   "source": [
    "### Problem 2, Model 3: Including *Nonlinear Components* in the *Frequency* of Voice to Explain Classification of PD\n",
    "We will use **the same column variables** as **Model 1**, and add in the explanatory variables **spread1, spread2, PPE - three nonlinear measures of fundamental frequency variation**. The addition of these variables allows us to include **nonlinearity** into our model, and investigate whether that would even further improve our first model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d414f71f",
   "metadata": {},
   "source": [
    "#### Using the KNNC Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "696540c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.8982.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       1.00      0.96      0.98        26\n",
      "\n",
      "    accuracy                           0.98        59\n",
      "   macro avg       0.99      0.98      0.98        59\n",
      "weighted avg       0.98      0.98      0.98        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9808.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this may take a while to run...\n",
    "all_model_approach_recs.append(knnc_predict(3, df_p2_balanced,\n",
    "             ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "              'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "              'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "              'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR',\n",
    "              'spread1', 'spread2', 'PPE'],\n",
    "             'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c75cfa",
   "metadata": {},
   "source": [
    "#### Using the Random Forest Classifier Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a06cb621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal hyperparameter is: 145.\n",
      "And the optimal CV score is: 0.9627.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.92      0.96        26\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9965.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this may take a while to run (longer than the KNNC approach)...\n",
    "all_model_approach_recs.append(rf_predict(3, df_p2_balanced,\n",
    "           ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "            'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "            'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "            'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR',\n",
    "            'spread1', 'spread2', 'PPE'],\n",
    "           'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37703cde",
   "metadata": {},
   "source": [
    "#### Using the Logistic Regression Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c41e793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV score is: 0.8061.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        33\n",
      "           1       0.74      0.77      0.75        26\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.78      0.78      0.78        59\n",
      "weighted avg       0.78      0.78      0.78        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9068.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this should run very quickly (no need to find optimal hyperparameter)\n",
    "all_model_approach_recs.append(logistic_predict(3, df_p2_balanced,\n",
    "                 ['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)',\n",
    "                  'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "                  'MDVP:Jitter(Abs)', 'MDVP:RAP',\n",
    "                  'MDVP:PPQ', 'Jitter:DDP', 'NHR', 'HNR',\n",
    "                  'spread1', 'spread2', 'PPE'],\n",
    "                 'status'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6919ab2",
   "metadata": {},
   "source": [
    "### Model Comparison and Some Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42b19f",
   "metadata": {},
   "source": [
    "See the DataFrame below for the **CV and ROC-AUC score** for each theoretical model and approach (double indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8b5ae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>131.0</td>\n",
       "      <td>0.952484</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700877</td>\n",
       "      <td>0.854312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877499</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.898071</td>\n",
       "      <td>0.995921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755406</td>\n",
       "      <td>0.829837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.962712</td>\n",
       "      <td>0.996503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806137</td>\n",
       "      <td>0.906760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          opt_hyperparam  opt_cv_score   roc_auc\n",
       "model_num model_approach                                        \n",
       "1         KNNC                       1.0      0.898188  0.961538\n",
       "          RFC                      131.0      0.952484  0.997669\n",
       "          LogR                       NaN      0.700877  0.854312\n",
       "2         KNNC                       1.0      0.877499  0.903846\n",
       "          RFC                      149.0      0.898071  0.995921\n",
       "          LogR                       NaN      0.755406  0.829837\n",
       "3         KNNC                       1.0      0.898188  0.980769\n",
       "          RFC                      145.0      0.962712  0.996503\n",
       "          LogR                       NaN      0.806137  0.906760"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_model_approach_recs)\n",
    "df.set_index(['model_num', 'model_approach'], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4108ff1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>RFC</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.962712</td>\n",
       "      <td>0.996503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>RFC</th>\n",
       "      <td>131.0</td>\n",
       "      <td>0.952484</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>RFC</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.898071</td>\n",
       "      <td>0.995921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877499</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806137</td>\n",
       "      <td>0.906760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755406</td>\n",
       "      <td>0.829837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700877</td>\n",
       "      <td>0.854312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          opt_hyperparam  opt_cv_score   roc_auc\n",
       "model_num model_approach                                        \n",
       "3         RFC                      145.0      0.962712  0.996503\n",
       "1         RFC                      131.0      0.952484  0.997669\n",
       "3         KNNC                       1.0      0.898188  0.980769\n",
       "1         KNNC                       1.0      0.898188  0.961538\n",
       "2         RFC                      149.0      0.898071  0.995921\n",
       "          KNNC                       1.0      0.877499  0.903846\n",
       "3         LogR                       NaN      0.806137  0.906760\n",
       "2         LogR                       NaN      0.755406  0.829837\n",
       "1         LogR                       NaN      0.700877  0.854312"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = ['opt_cv_score', 'roc_auc'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844d2a0",
   "metadata": {},
   "source": [
    "As illustrated above in the sorted DataFrame (by **CV Score** and then **ROC-AUC Score**, highest-to-lowest order), the **best overall model approach (method)** is **Random Forest Classifier (RFC)**, which performs better than KNNC (KNN Classifier) and Logistic Regression (which doesn’t have a hyperparameter) for every theoretical model.\n",
    "\n",
    "And overall, the **best theoretical model** is **Model 3** (*including nonlinear components in the frequency of voice to explain the classification of PD*). For each approach, Model 3 outperforms both other models (1 and 2), when we value CV score the most and then the ROC-AUC of a specific random test-split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e15d46",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38ebae",
   "metadata": {},
   "source": [
    "Until now, we have mostly utilized our theoretical understanding of the statistical properties of the distribution of objects such as the *frequency* and *amplitude* of voices as the underlying basis to our choice of explanatory variables used in our classification models. Nonetheless, in recent classes, we have also learned the **Principal Component Analysis (PCA)** approach, which can help reduce noises in our many explanatory variables through dimension reduction. \n",
    "\n",
    "Let us use **all** column variables (except for `name,` because it does not have any significance on its own, and `status,` because it is our explained variable) in our dataset as explanatory variables, transform those variables using the PCA approach with varying parameters regarding what percent of the variations across those variables should be left, and fit classification models using the KNNC, Random Forest Classifier, and Logistic Regression approaches, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5dfb5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our \"y\" status label\n",
    "Y_var = df_p2_balanced['status']\n",
    "\n",
    "# separate out the explanatory variables \n",
    "# (everything except our \"Y\" and the \"name\")\n",
    "X_vars = df_p2_balanced[['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
    "                         'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
    "                         'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
    "                         'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA',\n",
    "                         'spread1', 'spread2', 'D2', 'PPE']]\n",
    "\n",
    "# standardize the explanatory variables \n",
    "X_vars_st = StandardScaler().fit_transform(X_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206051f8",
   "metadata": {},
   "source": [
    "We experiment with multiple parameters (regarding what percent of the variations across our explanatory variables should be left), **from 1 (no PCA transformation) to 0.8 (80% variation left), decrement by 0.05 (5% variation),** and fit our classification models using the KNNC, Random Forest Classifier, and Logistic Regression methods respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce071ada",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->>> Using the KNNC Method <<<---\n",
      "—> The percent of variance left is: 1\n",
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.8742.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        33\n",
      "           1       1.00      0.77      0.87        26\n",
      "\n",
      "    accuracy                           0.90        59\n",
      "   macro avg       0.92      0.88      0.89        59\n",
      "weighted avg       0.91      0.90      0.90        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8846.\n",
      "\n",
      "\n",
      "--->>> Using the Random Forest Classifier Method <<<---\n",
      "—> The percent of variance left is: 1\n",
      "The optimal hyperparameter is: 100.\n",
      "And the optimal CV score is: 0.8742.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        33\n",
      "           1       1.00      0.77      0.87        26\n",
      "\n",
      "    accuracy                           0.90        59\n",
      "   macro avg       0.92      0.88      0.89        59\n",
      "weighted avg       0.91      0.90      0.90        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8660.\n",
      "\n",
      "\n",
      "--->>> Using the Logistic Regression Method <<<---\n",
      "—> The percent of variance left is: 1\n",
      "The CV score is: 0.7755.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79        33\n",
      "           1       0.75      0.69      0.72        26\n",
      "\n",
      "    accuracy                           0.76        59\n",
      "   macro avg       0.76      0.76      0.76        59\n",
      "weighted avg       0.76      0.76      0.76        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8811.\n",
      "\n",
      "\n",
      "--->>> Using the KNNC Method <<<---\n",
      "—> The percent of variance left is: 0.95\n",
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.9319.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.92      0.96        26\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9615.\n",
      "\n",
      "\n",
      "--->>> Using the Random Forest Classifier Method <<<---\n",
      "—> The percent of variance left is: 0.95\n",
      "The optimal hyperparameter is: 153.\n",
      "And the optimal CV score is: 0.9660.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        33\n",
      "           1       1.00      0.85      0.92        26\n",
      "\n",
      "    accuracy                           0.93        59\n",
      "   macro avg       0.95      0.92      0.93        59\n",
      "weighted avg       0.94      0.93      0.93        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9988.\n",
      "\n",
      "\n",
      "--->>> Using the Logistic Regression Method <<<---\n",
      "—> The percent of variance left is: 0.95\n",
      "The CV score is: 0.8403.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81        33\n",
      "           1       0.78      0.69      0.73        26\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.78      0.77      0.77        59\n",
      "weighted avg       0.78      0.78      0.78        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8683.\n",
      "\n",
      "\n",
      "--->>> Using the KNNC Method <<<---\n",
      "—> The percent of variance left is: 0.9\n",
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.8979.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.92      0.96        26\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9615.\n",
      "\n",
      "\n",
      "--->>> Using the Random Forest Classifier Method <<<---\n",
      "—> The percent of variance left is: 0.9\n",
      "The optimal hyperparameter is: 189.\n",
      "And the optimal CV score is: 0.9626.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        33\n",
      "           1       1.00      0.81      0.89        26\n",
      "\n",
      "    accuracy                           0.92        59\n",
      "   macro avg       0.93      0.90      0.91        59\n",
      "weighted avg       0.93      0.92      0.91        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9977.\n",
      "\n",
      "\n",
      "--->>> Using the Logistic Regression Method <<<---\n",
      "—> The percent of variance left is: 0.9\n",
      "The CV score is: 0.8300.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        33\n",
      "           1       0.82      0.69      0.75        26\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.80      0.79      0.79        59\n",
      "weighted avg       0.80      0.80      0.79        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8566.\n",
      "\n",
      "\n",
      "--->>> Using the KNNC Method <<<---\n",
      "—> The percent of variance left is: 0.85\n",
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.9081.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        33\n",
      "           1       1.00      0.92      0.96        26\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9615.\n",
      "\n",
      "\n",
      "--->>> Using the Random Forest Classifier Method <<<---\n",
      "—> The percent of variance left is: 0.85\n",
      "The optimal hyperparameter is: 148.\n",
      "And the optimal CV score is: 0.9558.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        33\n",
      "           1       1.00      0.85      0.92        26\n",
      "\n",
      "    accuracy                           0.93        59\n",
      "   macro avg       0.95      0.92      0.93        59\n",
      "weighted avg       0.94      0.93      0.93        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9953.\n",
      "\n",
      "\n",
      "--->>> Using the Logistic Regression Method <<<---\n",
      "—> The percent of variance left is: 0.85\n",
      "The CV score is: 0.8131.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81        33\n",
      "           1       0.78      0.69      0.73        26\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.78      0.77      0.77        59\n",
      "weighted avg       0.78      0.78      0.78        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8834.\n",
      "\n",
      "\n",
      "--->>> Using the KNNC Method <<<---\n",
      "—> The percent of variance left is: 0.8\n",
      "The optimal hyperparameter is: 1.\n",
      "And the optimal CV score is: 0.9115.\n",
      "\n",
      "Using the KNNC Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        33\n",
      "           1       1.00      0.88      0.94        26\n",
      "\n",
      "    accuracy                           0.95        59\n",
      "   macro avg       0.96      0.94      0.95        59\n",
      "weighted avg       0.95      0.95      0.95        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9423.\n",
      "\n",
      "\n",
      "--->>> Using the Random Forest Classifier Method <<<---\n",
      "—> The percent of variance left is: 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal hyperparameter is: 108.\n",
      "And the optimal CV score is: 0.9592.\n",
      "\n",
      "Using the Random Forest Classifier Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        33\n",
      "           1       1.00      0.81      0.89        26\n",
      "\n",
      "    accuracy                           0.92        59\n",
      "   macro avg       0.93      0.90      0.91        59\n",
      "weighted avg       0.93      0.92      0.91        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.9953.\n",
      "\n",
      "\n",
      "--->>> Using the Logistic Regression Method <<<---\n",
      "—> The percent of variance left is: 0.8\n",
      "The CV score is: 0.7757.\n",
      "\n",
      "Using the Logistic Regression Approach, \n",
      "Based on a random train-test split (using random_state = 0):\n",
      "The classification report for the test data is:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        33\n",
      "           1       0.74      0.77      0.75        26\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.78      0.78      0.78        59\n",
      "weighted avg       0.78      0.78      0.78        59\n",
      "\n",
      "And the ROC-AUC score for the test data is 0.8858.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this for loop will take a long time if you want to re-run it\n",
    "# mostly because the RFC fitting take a while\n",
    "# \n",
    "for var in [1, 0.95, 0.90, 0.85, 0.8]:\n",
    "    \n",
    "    pc1 = PCA(var).fit(X_vars_st)\n",
    "    \n",
    "    X1_transformed = pc1.transform(X_vars_st)\n",
    "    \n",
    "    # instantiate fit (using transformed [projected] independent vars)\n",
    "    \n",
    "    print(\"--->>> Using the KNNC Method <<<---\")\n",
    "    print(\"—> The percent of variance left is: {}\".format(var))\n",
    "    \n",
    "    all_model_approach_recs.append(knnc_predict(\"4, var = {}\".format(var), \n",
    "    df_p2_balanced, [], 'status', use_df = False, x_obj = X1_transformed))\n",
    "    print()\n",
    "    \n",
    "    print(\"--->>> Using the Random Forest Classifier Method <<<---\")\n",
    "    print(\"—> The percent of variance left is: {}\".format(var))\n",
    "    \n",
    "    all_model_approach_recs.append(rf_predict(\"4, var = {}\".format(var), \n",
    "    df_p2_balanced, [], 'status', use_df = False, x_obj = X1_transformed))\n",
    "    print()\n",
    "    \n",
    "    print(\"--->>> Using the Logistic Regression Method <<<---\")\n",
    "    print(\"—> The percent of variance left is: {}\".format(var))\n",
    "    \n",
    "    all_model_approach_recs.append(logistic_predict(\"4, var = {}\".format(var), \n",
    "    df_p2_balanced, [], 'status', use_df = False, x_obj = X1_transformed))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f52eb2",
   "metadata": {},
   "source": [
    "See the DataFrame below for the **CV and ROC-AUC score** for each theoretical model and approach (double indices), following **PCA with varying parameters (% of variance left)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50105198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.865967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775511</td>\n",
       "      <td>0.881119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.95</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931853</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.966043</td>\n",
       "      <td>0.998834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840327</td>\n",
       "      <td>0.868298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.9</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.962595</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830041</td>\n",
       "      <td>0.856643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.85</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908124</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.955757</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813092</td>\n",
       "      <td>0.883450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.8</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911514</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.959205</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775745</td>\n",
       "      <td>0.885781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              opt_hyperparam  opt_cv_score   roc_auc\n",
       "model_num     model_approach                                        \n",
       "4, var = 1    KNNC                       1.0      0.874167  0.884615\n",
       "              RFC                      100.0      0.874167  0.865967\n",
       "              LogR                       NaN      0.775511  0.881119\n",
       "4, var = 0.95 KNNC                       1.0      0.931853  0.961538\n",
       "              RFC                      153.0      0.966043  0.998834\n",
       "              LogR                       NaN      0.840327  0.868298\n",
       "4, var = 0.9  KNNC                       1.0      0.897896  0.961538\n",
       "              RFC                      189.0      0.962595  0.997669\n",
       "              LogR                       NaN      0.830041  0.856643\n",
       "4, var = 0.85 KNNC                       1.0      0.908124  0.961538\n",
       "              RFC                      148.0      0.955757  0.995338\n",
       "              LogR                       NaN      0.813092  0.883450\n",
       "4, var = 0.8  KNNC                       1.0      0.911514  0.942308\n",
       "              RFC                      108.0      0.959205  0.995338\n",
       "              LogR                       NaN      0.775745  0.885781"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-create df from updated overall record \n",
    "df = pd.DataFrame(all_model_approach_recs)\n",
    "df.set_index(['model_num', 'model_approach'], inplace = True)\n",
    "\n",
    "# replace all np.NaN in boolean expression with False for boolean indexing\n",
    "df.iloc[df.index.get_level_values('model_num').str.contains(\"4\", na = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197dea4c",
   "metadata": {},
   "source": [
    "If we sort the DataFrame above by CV and then ROC-AUC score (in that order of priority) from highest to lowest, we can clearly see that, in terms of the model approach, **RFC** still outperforms KNNC almost every time—and both of them outperform the Logistic Regression approach. This is consistent with our three theory-based models in the previous section. \n",
    "\n",
    "And amongst all model approaches, the parameter of **95% variation left in PCA** outperforms other parameters with less variation left, all of which also outperform the scenario where 100% of the variation is preserved (where PCA is *de facto* not implemented). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad4f5bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4, var = 0.95</th>\n",
       "      <th>RFC</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.966043</td>\n",
       "      <td>0.998834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.9</th>\n",
       "      <th>RFC</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.962595</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.8</th>\n",
       "      <th>RFC</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.959205</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.85</th>\n",
       "      <th>RFC</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.955757</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.95</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931853</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.8</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911514</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.85</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908124</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.9</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4, var = 1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.865967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.95</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840327</td>\n",
       "      <td>0.868298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.9</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830041</td>\n",
       "      <td>0.856643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.85</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813092</td>\n",
       "      <td>0.883450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.8</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775745</td>\n",
       "      <td>0.885781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 1</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775511</td>\n",
       "      <td>0.881119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              opt_hyperparam  opt_cv_score   roc_auc\n",
       "model_num     model_approach                                        \n",
       "4, var = 0.95 RFC                      153.0      0.966043  0.998834\n",
       "4, var = 0.9  RFC                      189.0      0.962595  0.997669\n",
       "4, var = 0.8  RFC                      108.0      0.959205  0.995338\n",
       "4, var = 0.85 RFC                      148.0      0.955757  0.995338\n",
       "4, var = 0.95 KNNC                       1.0      0.931853  0.961538\n",
       "4, var = 0.8  KNNC                       1.0      0.911514  0.942308\n",
       "4, var = 0.85 KNNC                       1.0      0.908124  0.961538\n",
       "4, var = 0.9  KNNC                       1.0      0.897896  0.961538\n",
       "4, var = 1    KNNC                       1.0      0.874167  0.884615\n",
       "              RFC                      100.0      0.874167  0.865967\n",
       "4, var = 0.95 LogR                       NaN      0.840327  0.868298\n",
       "4, var = 0.9  LogR                       NaN      0.830041  0.856643\n",
       "4, var = 0.85 LogR                       NaN      0.813092  0.883450\n",
       "4, var = 0.8  LogR                       NaN      0.775745  0.885781\n",
       "4, var = 1    LogR                       NaN      0.775511  0.881119"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df.index.get_level_values('model_num').str.contains(\"4\", na = False)]\\\n",
    ".sort_values(by = ['opt_cv_score', 'roc_auc'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab5e99",
   "metadata": {},
   "source": [
    "Let us also take a look at the overall comparison among all classification models that we have experimented with so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a8e3bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>131.0</td>\n",
       "      <td>0.952484</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700877</td>\n",
       "      <td>0.854312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877499</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.898071</td>\n",
       "      <td>0.995921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755406</td>\n",
       "      <td>0.829837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.962712</td>\n",
       "      <td>0.996503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806137</td>\n",
       "      <td>0.906760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.865967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775511</td>\n",
       "      <td>0.881119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.95</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931853</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.966043</td>\n",
       "      <td>0.998834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840327</td>\n",
       "      <td>0.868298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.9</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.962595</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830041</td>\n",
       "      <td>0.856643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.85</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908124</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.955757</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813092</td>\n",
       "      <td>0.883450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4, var = 0.8</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911514</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.959205</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775745</td>\n",
       "      <td>0.885781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              opt_hyperparam  opt_cv_score   roc_auc\n",
       "model_num     model_approach                                        \n",
       "1             KNNC                       1.0      0.898188  0.961538\n",
       "              RFC                      131.0      0.952484  0.997669\n",
       "              LogR                       NaN      0.700877  0.854312\n",
       "2             KNNC                       1.0      0.877499  0.903846\n",
       "              RFC                      149.0      0.898071  0.995921\n",
       "              LogR                       NaN      0.755406  0.829837\n",
       "3             KNNC                       1.0      0.898188  0.980769\n",
       "              RFC                      145.0      0.962712  0.996503\n",
       "              LogR                       NaN      0.806137  0.906760\n",
       "4, var = 1    KNNC                       1.0      0.874167  0.884615\n",
       "              RFC                      100.0      0.874167  0.865967\n",
       "              LogR                       NaN      0.775511  0.881119\n",
       "4, var = 0.95 KNNC                       1.0      0.931853  0.961538\n",
       "              RFC                      153.0      0.966043  0.998834\n",
       "              LogR                       NaN      0.840327  0.868298\n",
       "4, var = 0.9  KNNC                       1.0      0.897896  0.961538\n",
       "              RFC                      189.0      0.962595  0.997669\n",
       "              LogR                       NaN      0.830041  0.856643\n",
       "4, var = 0.85 KNNC                       1.0      0.908124  0.961538\n",
       "              RFC                      148.0      0.955757  0.995338\n",
       "              LogR                       NaN      0.813092  0.883450\n",
       "4, var = 0.8  KNNC                       1.0      0.911514  0.942308\n",
       "              RFC                      108.0      0.959205  0.995338\n",
       "              LogR                       NaN      0.775745  0.885781"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d90fd",
   "metadata": {},
   "source": [
    "And, after sorting the DataFrame in the same manner as described above (by CV and then ROC-AUC score, in order of priority), we see that indeed, across all model approaches, the optimal PCA parameter of **95% variation left** contributes to a model that **outperforms the already optimal Model 3** in our previous, theory-based section. \n",
    "\n",
    "Meanwhile, note that if we were to include all possible explanatory variables and not reduce any noise through PCA (**100% variation preserved**), the resulting model `4, var = 1` would very often **perform worse** than even our **non-optimal Model 2 and Model 1** from the previous section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddea7773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>opt_hyperparam</th>\n",
       "      <th>opt_cv_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_num</th>\n",
       "      <th>model_approach</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4, var = 0.95</th>\n",
       "      <th>RFC</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.966043</td>\n",
       "      <td>0.998834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>RFC</th>\n",
       "      <td>145.0</td>\n",
       "      <td>0.962712</td>\n",
       "      <td>0.996503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.9</th>\n",
       "      <th>RFC</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.962595</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.8</th>\n",
       "      <th>RFC</th>\n",
       "      <td>108.0</td>\n",
       "      <td>0.959205</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.85</th>\n",
       "      <th>RFC</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.955757</td>\n",
       "      <td>0.995338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>RFC</th>\n",
       "      <td>131.0</td>\n",
       "      <td>0.952484</td>\n",
       "      <td>0.997669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.95</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931853</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.8</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911514</td>\n",
       "      <td>0.942308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.85</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908124</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>RFC</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.898071</td>\n",
       "      <td>0.995921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.9</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897896</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877499</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4, var = 1</th>\n",
       "      <th>KNNC</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.865967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.95</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840327</td>\n",
       "      <td>0.868298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.9</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830041</td>\n",
       "      <td>0.856643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.85</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813092</td>\n",
       "      <td>0.883450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806137</td>\n",
       "      <td>0.906760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 0.8</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775745</td>\n",
       "      <td>0.885781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4, var = 1</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775511</td>\n",
       "      <td>0.881119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755406</td>\n",
       "      <td>0.829837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>LogR</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700877</td>\n",
       "      <td>0.854312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              opt_hyperparam  opt_cv_score   roc_auc\n",
       "model_num     model_approach                                        \n",
       "4, var = 0.95 RFC                      153.0      0.966043  0.998834\n",
       "3             RFC                      145.0      0.962712  0.996503\n",
       "4, var = 0.9  RFC                      189.0      0.962595  0.997669\n",
       "4, var = 0.8  RFC                      108.0      0.959205  0.995338\n",
       "4, var = 0.85 RFC                      148.0      0.955757  0.995338\n",
       "1             RFC                      131.0      0.952484  0.997669\n",
       "4, var = 0.95 KNNC                       1.0      0.931853  0.961538\n",
       "4, var = 0.8  KNNC                       1.0      0.911514  0.942308\n",
       "4, var = 0.85 KNNC                       1.0      0.908124  0.961538\n",
       "3             KNNC                       1.0      0.898188  0.980769\n",
       "1             KNNC                       1.0      0.898188  0.961538\n",
       "2             RFC                      149.0      0.898071  0.995921\n",
       "4, var = 0.9  KNNC                       1.0      0.897896  0.961538\n",
       "2             KNNC                       1.0      0.877499  0.903846\n",
       "4, var = 1    KNNC                       1.0      0.874167  0.884615\n",
       "              RFC                      100.0      0.874167  0.865967\n",
       "4, var = 0.95 LogR                       NaN      0.840327  0.868298\n",
       "4, var = 0.9  LogR                       NaN      0.830041  0.856643\n",
       "4, var = 0.85 LogR                       NaN      0.813092  0.883450\n",
       "3             LogR                       NaN      0.806137  0.906760\n",
       "4, var = 0.8  LogR                       NaN      0.775745  0.885781\n",
       "4, var = 1    LogR                       NaN      0.775511  0.881119\n",
       "2             LogR                       NaN      0.755406  0.829837\n",
       "1             LogR                       NaN      0.700877  0.854312"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = ['opt_cv_score', 'roc_auc'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc1c7f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f65e24d",
   "metadata": {},
   "source": [
    "### Problem 3:\n",
    "\n",
    "Dataset for final project Initial ideas:  Find 2 possible open datasets (or a way to construct a dataset), and present the following:\n",
    "\n",
    "Context of the dataset: What is interesting about the dataset? What questions could you ask that are interesting? How would you first explore the data? (No need to perform exploration at this moment)\n",
    "\n",
    "Methodology: How do you think you want to answer your question? \n",
    "\n",
    "Present links for references if available. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f216e",
   "metadata": {},
   "source": [
    "### **Idea 1: <a href = \"https://www.kaggle.com/aljarah/xAPI-Edu-Data\">Students' Academic Performance Dataset</a> (from Kaggle)**\n",
    "\n",
    "- What we feel is interesting (and novel) about this dataset is that, in addition to the more conventional demographic and academic background features, **behavior features** of each student (as an individual observation) and their immediate microsystem (i.e. parents/family), such as \"raised hand in class, opening resources, answering survey by parents, and school satisfaction\" are **also included as explanatory variables** to a student's grade/mark (as a measure of academic performance).\n",
    "    - We should thank the learner activity tracker tool in the learning management system (LMS) for keeping track of the micro-level behavior factors of individual students.\n",
    "\n",
    "\n",
    "- This dataset would require us to utilize **classification models**, as the explained variable `Class` is a **categorical (thus discrete and non-continuous) variable** that consists of three classification categories: \n",
    "    1. Low-Level: interval includes values from 0 to 69,\n",
    "    2. Middle-Level: interval includes values from 70 to 89,\n",
    "    3. High-Level: interval includes values from 90-100. <br>(See the \"Description\" section of the dataset for more details)\n",
    "    \n",
    "    \n",
    "- In addition to experimenting with and establishing some (several, perhaps) **optimally performing classification models**—so that we could predict **how likely**, on average, *ceteris paribus*, an individual, with a certain set of traits, would belong to one of the three categories of the explained variable `Class`, with what we are currently learning (about causal inference), we also hope to establish the **existence/degree/extent of causal relationships** between one or some of the explanatory variable(s) with `Class`, and may even compare and evaluate **which factor** might have the **most economically/statistically significant (strongest) influence**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc257e54",
   "metadata": {},
   "source": [
    "### **Idea 2: <a href = \"https://www.kaggle.com/paultimothymooney/minneapolis-police-stops-and-police-violence\">Minneapolis Police Stops and Police Violence</a> (from Kaggle)**\n",
    "\n",
    "**Context of the dataset**: \n",
    "\n",
    "This data set is openly available on Kaggle. It is a database of information about police stops and police use of force in Minneapolis from an open government database. Minneapolis is the city where George Floyd was choked to death by a police officer, sparking nationwide BLM protests. This data provides insight into the general conduct of police in Minneapolis, which puts George Floyd’s death into a larger context. It can help answer the core questions behind the nationwide protests: Are police discriminating? And are they using unnecessary force? \n",
    "\n",
    "The data set includes information on police stops, including the race, gender, and neighborhood of the person stopped, as well as information about whether the person was searched and the reason for the stop. The dataset also includes demographic information on people who police officers used force on, as well as data on the reason for the police interaction and \"type of resistance\" (tensing is listed as a type of resistance). We are interested in whether we can predict who was stopped, searched, or experienced police force based on demographic information. We also want to describe policing in Minneapolis and answer the following: what reasons are police stopping people for? What types of interactions lead to violence? Are certain police stops more likely to end in police force than others? \n",
    "\n",
    "**Methodology**: \n",
    "\n",
    "We would first use descriptive data to generally describe police interactions in Minneapolis. Then we would use predictive models to see if we can explain which interactions lead to searches and/or violent encounters using data on the reason for the interaction, neighborhood and demographic information on the person stopped, and type of resistance of the person stopped.\n",
    "\n",
    "**Links for References**:\n",
    "- https://www.kaggle.com/paultimothymooney/minneapolis-police-stops-and-police-violence\n",
    "- https://www.nytimes.com/article/george-floyd.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
